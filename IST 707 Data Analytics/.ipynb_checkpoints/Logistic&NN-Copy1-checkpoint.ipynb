{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lakshya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\The Lakshya\\Anaconda3\\lib\\site-packages\\statsmodels\\tools\\_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, cross_validate, ShuffleSplit, LeaveOneOut\n",
    "from sklearn import metrics\n",
    "from matplotlib import pyplot as plt\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/processedData.csv')\n",
    "# dataOS = pd.read_csv('data/processedDataOverSampled.csv')\n",
    "# dataSMOTE = pd.read_csv('data/processedDataSMOTE.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop('Unnamed: 0',axis = 1)\n",
    "# dataOS = dataOS.drop('Unnamed: 0',axis = 1)\n",
    "# dataSMOTE = dataSMOTE.drop('Unnamed: 0',axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spliting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertYN(x):\n",
    "    if x=='yes':\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=data['y']\n",
    "X=data.drop(columns=['y'])\n",
    "y=y.apply(convertYN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=0)\n",
    "X_SMOTE, y_SMOTE = sm.fit_resample(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yOS=dataOS['y']\n",
    "# XOS=dataOS.drop(columns=['y'])\n",
    "# yOS=yOS.apply(convertYN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ySMOTE=dataSMOTE['y']\n",
    "# XSMOTE=dataSMOTE.drop(columns=['y'])\n",
    "# ySMOTE=ySMOTE.apply(convertYN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_trainOS, X_testOS, y_trainOS, y_testOS = train_test_split(XOS, yOS, test_size=0.3, random_state=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_trainSMOTE, X_testSMOTE, y_trainSMOTE, y_testSMOTE = train_test_split(XSMOTE, ySMOTE, test_size=0.3, random_state=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "logr_pipe = make_pipeline( LogisticRegression(solver='lbfgs',max_iter=500))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unbalance data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Lr_Imb=logr_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 90.81%\n",
      "Balanced Accuracy: 68.86%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95     10934\n",
      "           1       0.67      0.40      0.50      1423\n",
      "\n",
      "    accuracy                           0.91     12357\n",
      "   macro avg       0.80      0.69      0.73     12357\n",
      "weighted avg       0.90      0.91      0.90     12357\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10648</td>\n",
       "      <td>286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>849</td>\n",
       "      <td>574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0      0    1\n",
       "y                \n",
       "0      10648  286\n",
       "1        849  574"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model_Lr_Imb.predict(X_test)\n",
    "print(f\"Accuracy: {round(metrics.accuracy_score(y_test, y_pred)*100, 2)}%\")\n",
    "print(f\"Balanced Accuracy: {round(metrics.balanced_accuracy_score(y_test, y_pred)*100, 2)}%\")\n",
    "\n",
    "print(classification_report(y_test,y_pred))\n",
    "df_confusion = pd.crosstab(y_test, y_pred)\n",
    "df_confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\The Lakshya\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "model_Lr_SMOTE=logr_pipe.fit(X_SMOTE, y_SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 90.71%\n",
      "Balanced Accuracy: 72.01%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.95     10934\n",
      "           1       0.63      0.48      0.54      1423\n",
      "\n",
      "    accuracy                           0.91     12357\n",
      "   macro avg       0.78      0.72      0.75     12357\n",
      "weighted avg       0.90      0.91      0.90     12357\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10530</td>\n",
       "      <td>404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>744</td>\n",
       "      <td>679</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0      0    1\n",
       "y                \n",
       "0      10530  404\n",
       "1        744  679"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model_Lr_SMOTE.predict(X_test)\n",
    "print(f\"Accuracy: {round(metrics.accuracy_score(y_test, y_pred)*100, 2)}%\")\n",
    "print(f\"Balanced Accuracy: {round(metrics.balanced_accuracy_score(y_test, y_pred)*100, 2)}%\")\n",
    "\n",
    "print(classification_report(y_test,y_pred))\n",
    "df_confusion = pd.crosstab(y_test, y_pred)\n",
    "df_confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 0.01, 'random_state': 12, 'solver': 'liblinear'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgr= LogisticRegression()\n",
    "param_grid = {'solver': ['liblinear', 'lbfgs',  'saga'],'C':[0.001,0.01,0.1,1,10],'random_state':[12]}\n",
    "#use gridsearch \n",
    "lgr_gscv = GridSearchCV(lgr, param_grid, cv=4, n_jobs=-1)\n",
    "#fit model to data\n",
    "lgr_gscv.fit(X_SMOTE, y_SMOTE)\n",
    "print(\"Best parameters:\")\n",
    "lgr_gscv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_clf = LogisticRegression(C= 0.01, random_state= 12, solver='liblinear')\n",
    "LRModel = LR_clf.fit(X_SMOTE, y_SMOTE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 91.2%\n",
      "Balanced Accuracy: 74.15%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95     10934\n",
      "           1       0.65      0.52      0.58      1423\n",
      "\n",
      "    accuracy                           0.91     12357\n",
      "   macro avg       0.79      0.74      0.76     12357\n",
      "weighted avg       0.91      0.91      0.91     12357\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10530</td>\n",
       "      <td>404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>683</td>\n",
       "      <td>740</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0      0    1\n",
       "y                \n",
       "0      10530  404\n",
       "1        683  740"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = LR_clf.predict(X_test)\n",
    "print(f\"Accuracy: {round(metrics.accuracy_score(y_test, y_pred)*100, 2)}%\")\n",
    "print(f\"Balanced Accuracy: {round(metrics.balanced_accuracy_score(y_test, y_pred)*100, 2)}%\")\n",
    "\n",
    "print(classification_report(y_test,y_pred))\n",
    "df_confusion = pd.crosstab(y_test, y_pred)\n",
    "df_confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some_file.py\n",
    "import sys\n",
    "# insert at 1, 0 is the script path (or '' in REPL)\n",
    "sys.path.insert(1, '/home/lkgupta/.local/lib/python3.7/site-packages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "\n",
    "from keras.regularizers import l1_l2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Layer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_25 (Dense)             (None, 16)                944       \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 1,089\n",
      "Trainable params: 1,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "#model.add(Dense(500, activation='relu', input_dim=58))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Dense(16, activation='relu',input_dim=58))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "#model.output_shape\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_std = scaler.transform(X_train)\n",
    "X_test_std = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28831 samples, validate on 12357 samples\n",
      "Epoch 1/800\n",
      "28831/28831 [==============================] - 1s 41us/step - loss: 0.4544 - accuracy: 0.8592 - val_loss: 0.3656 - val_accuracy: 0.8848\n",
      "Epoch 2/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.3591 - accuracy: 0.8853 - val_loss: 0.3149 - val_accuracy: 0.8848\n",
      "Epoch 3/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.3248 - accuracy: 0.8877 - val_loss: 0.2893 - val_accuracy: 0.8848\n",
      "Epoch 4/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.3063 - accuracy: 0.8878 - val_loss: 0.2722 - val_accuracy: 0.8849\n",
      "Epoch 5/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.2889 - accuracy: 0.8886 - val_loss: 0.2598 - val_accuracy: 0.8853\n",
      "Epoch 6/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.2736 - accuracy: 0.8908 - val_loss: 0.2496 - val_accuracy: 0.8869\n",
      "Epoch 7/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.2688 - accuracy: 0.8908 - val_loss: 0.2414 - val_accuracy: 0.8878\n",
      "Epoch 8/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.2615 - accuracy: 0.8923 - val_loss: 0.2344 - val_accuracy: 0.8895\n",
      "Epoch 9/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.2526 - accuracy: 0.8941 - val_loss: 0.2285 - val_accuracy: 0.8899\n",
      "Epoch 10/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.2482 - accuracy: 0.8936 - val_loss: 0.2237 - val_accuracy: 0.8913\n",
      "Epoch 11/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.2433 - accuracy: 0.8947 - val_loss: 0.2195 - val_accuracy: 0.8916\n",
      "Epoch 12/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.2407 - accuracy: 0.8968 - val_loss: 0.2164 - val_accuracy: 0.8922\n",
      "Epoch 13/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.2353 - accuracy: 0.8962 - val_loss: 0.2135 - val_accuracy: 0.8934\n",
      "Epoch 14/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.2324 - accuracy: 0.8966 - val_loss: 0.2110 - val_accuracy: 0.8941\n",
      "Epoch 15/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.2276 - accuracy: 0.8979 - val_loss: 0.2090 - val_accuracy: 0.8945\n",
      "Epoch 16/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.2254 - accuracy: 0.8980 - val_loss: 0.2072 - val_accuracy: 0.8951\n",
      "Epoch 17/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.2268 - accuracy: 0.8979 - val_loss: 0.2058 - val_accuracy: 0.8956\n",
      "Epoch 18/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.2236 - accuracy: 0.8997 - val_loss: 0.2045 - val_accuracy: 0.8964\n",
      "Epoch 19/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.2227 - accuracy: 0.8985 - val_loss: 0.2035 - val_accuracy: 0.8967\n",
      "Epoch 20/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.2183 - accuracy: 0.9000 - val_loss: 0.2025 - val_accuracy: 0.8970\n",
      "Epoch 21/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.2171 - accuracy: 0.9006 - val_loss: 0.2016 - val_accuracy: 0.8974\n",
      "Epoch 22/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.2176 - accuracy: 0.9015 - val_loss: 0.2008 - val_accuracy: 0.8976\n",
      "Epoch 23/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.2175 - accuracy: 0.8994 - val_loss: 0.2003 - val_accuracy: 0.8980\n",
      "Epoch 24/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.2148 - accuracy: 0.9001 - val_loss: 0.1996 - val_accuracy: 0.8979\n",
      "Epoch 25/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.2125 - accuracy: 0.8998 - val_loss: 0.1991 - val_accuracy: 0.8975\n",
      "Epoch 26/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.2131 - accuracy: 0.9015 - val_loss: 0.1986 - val_accuracy: 0.8982\n",
      "Epoch 27/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.2129 - accuracy: 0.8999 - val_loss: 0.1980 - val_accuracy: 0.8984\n",
      "Epoch 28/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.2101 - accuracy: 0.9005 - val_loss: 0.1974 - val_accuracy: 0.8988\n",
      "Epoch 29/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.2114 - accuracy: 0.9023 - val_loss: 0.1971 - val_accuracy: 0.8988\n",
      "Epoch 30/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.2116 - accuracy: 0.9012 - val_loss: 0.1968 - val_accuracy: 0.8993\n",
      "Epoch 31/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.2094 - accuracy: 0.9009 - val_loss: 0.1966 - val_accuracy: 0.8991\n",
      "Epoch 32/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.2065 - accuracy: 0.9014 - val_loss: 0.1962 - val_accuracy: 0.8994\n",
      "Epoch 33/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.2100 - accuracy: 0.9007 - val_loss: 0.1959 - val_accuracy: 0.8998\n",
      "Epoch 34/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.2070 - accuracy: 0.9019 - val_loss: 0.1956 - val_accuracy: 0.9002\n",
      "Epoch 35/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.2060 - accuracy: 0.9017 - val_loss: 0.1954 - val_accuracy: 0.9005\n",
      "Epoch 36/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.2060 - accuracy: 0.9024 - val_loss: 0.1952 - val_accuracy: 0.9009\n",
      "Epoch 37/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.2061 - accuracy: 0.9027 - val_loss: 0.1949 - val_accuracy: 0.9010\n",
      "Epoch 38/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.2041 - accuracy: 0.9022 - val_loss: 0.1946 - val_accuracy: 0.9014\n",
      "Epoch 39/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.2040 - accuracy: 0.9037 - val_loss: 0.1943 - val_accuracy: 0.9014\n",
      "Epoch 40/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.2033 - accuracy: 0.9023 - val_loss: 0.1941 - val_accuracy: 0.9014\n",
      "Epoch 41/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.2040 - accuracy: 0.9039 - val_loss: 0.1939 - val_accuracy: 0.9014\n",
      "Epoch 42/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.2054 - accuracy: 0.9020 - val_loss: 0.1938 - val_accuracy: 0.9018\n",
      "Epoch 43/800\n",
      "28831/28831 [==============================] - 0s 16us/step - loss: 0.2043 - accuracy: 0.9015 - val_loss: 0.1937 - val_accuracy: 0.9015\n",
      "Epoch 44/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.2002 - accuracy: 0.9032 - val_loss: 0.1934 - val_accuracy: 0.9022\n",
      "Epoch 45/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.2036 - accuracy: 0.9019 - val_loss: 0.1932 - val_accuracy: 0.9024\n",
      "Epoch 46/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.2027 - accuracy: 0.9039 - val_loss: 0.1930 - val_accuracy: 0.9031\n",
      "Epoch 47/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.2022 - accuracy: 0.9037 - val_loss: 0.1928 - val_accuracy: 0.9031\n",
      "Epoch 48/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.2009 - accuracy: 0.9047 - val_loss: 0.1927 - val_accuracy: 0.9032\n",
      "Epoch 49/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.2013 - accuracy: 0.9042 - val_loss: 0.1926 - val_accuracy: 0.9034\n",
      "Epoch 50/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.2012 - accuracy: 0.9034 - val_loss: 0.1924 - val_accuracy: 0.9034\n",
      "Epoch 51/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.2003 - accuracy: 0.9023 - val_loss: 0.1924 - val_accuracy: 0.9035\n",
      "Epoch 52/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1997 - accuracy: 0.9042 - val_loss: 0.1922 - val_accuracy: 0.9036\n",
      "Epoch 53/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.2002 - accuracy: 0.9045 - val_loss: 0.1920 - val_accuracy: 0.9039\n",
      "Epoch 54/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1988 - accuracy: 0.9049 - val_loss: 0.1919 - val_accuracy: 0.9043\n",
      "Epoch 55/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1992 - accuracy: 0.9032 - val_loss: 0.1918 - val_accuracy: 0.9040\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/800\n",
      "28831/28831 [==============================] - 0s 16us/step - loss: 0.1989 - accuracy: 0.9038 - val_loss: 0.1917 - val_accuracy: 0.9043\n",
      "Epoch 57/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1993 - accuracy: 0.9046 - val_loss: 0.1917 - val_accuracy: 0.9042\n",
      "Epoch 58/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1976 - accuracy: 0.9049 - val_loss: 0.1917 - val_accuracy: 0.9042\n",
      "Epoch 59/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1972 - accuracy: 0.9050 - val_loss: 0.1914 - val_accuracy: 0.9042\n",
      "Epoch 60/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1979 - accuracy: 0.9049 - val_loss: 0.1913 - val_accuracy: 0.9043\n",
      "Epoch 61/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1969 - accuracy: 0.9052 - val_loss: 0.1912 - val_accuracy: 0.9045\n",
      "Epoch 62/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1994 - accuracy: 0.9054 - val_loss: 0.1912 - val_accuracy: 0.9044\n",
      "Epoch 63/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1991 - accuracy: 0.9043 - val_loss: 0.1911 - val_accuracy: 0.9048\n",
      "Epoch 64/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1971 - accuracy: 0.9051 - val_loss: 0.1910 - val_accuracy: 0.9051\n",
      "Epoch 65/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1972 - accuracy: 0.9050 - val_loss: 0.1909 - val_accuracy: 0.9053\n",
      "Epoch 66/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1970 - accuracy: 0.9048 - val_loss: 0.1908 - val_accuracy: 0.9055\n",
      "Epoch 67/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1964 - accuracy: 0.9048 - val_loss: 0.1907 - val_accuracy: 0.9052\n",
      "Epoch 68/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1979 - accuracy: 0.9061 - val_loss: 0.1906 - val_accuracy: 0.9055\n",
      "Epoch 69/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1947 - accuracy: 0.9064 - val_loss: 0.1905 - val_accuracy: 0.9054\n",
      "Epoch 70/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1967 - accuracy: 0.9053 - val_loss: 0.1904 - val_accuracy: 0.9055\n",
      "Epoch 71/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1959 - accuracy: 0.9060 - val_loss: 0.1903 - val_accuracy: 0.9056\n",
      "Epoch 72/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1952 - accuracy: 0.9064 - val_loss: 0.1902 - val_accuracy: 0.9055\n",
      "Epoch 73/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1954 - accuracy: 0.9054 - val_loss: 0.1902 - val_accuracy: 0.9057\n",
      "Epoch 74/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1960 - accuracy: 0.9058 - val_loss: 0.1902 - val_accuracy: 0.9055\n",
      "Epoch 75/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1965 - accuracy: 0.9047 - val_loss: 0.1901 - val_accuracy: 0.9057\n",
      "Epoch 76/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1946 - accuracy: 0.9048 - val_loss: 0.1901 - val_accuracy: 0.9058\n",
      "Epoch 77/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1965 - accuracy: 0.9056 - val_loss: 0.1900 - val_accuracy: 0.9059\n",
      "Epoch 78/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1965 - accuracy: 0.9059 - val_loss: 0.1899 - val_accuracy: 0.9057\n",
      "Epoch 79/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1951 - accuracy: 0.9055 - val_loss: 0.1899 - val_accuracy: 0.9056\n",
      "Epoch 80/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1937 - accuracy: 0.9067 - val_loss: 0.1898 - val_accuracy: 0.9059\n",
      "Epoch 81/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1962 - accuracy: 0.9054 - val_loss: 0.1897 - val_accuracy: 0.9060\n",
      "Epoch 82/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1939 - accuracy: 0.9068 - val_loss: 0.1897 - val_accuracy: 0.9059\n",
      "Epoch 83/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1939 - accuracy: 0.9058 - val_loss: 0.1896 - val_accuracy: 0.9063\n",
      "Epoch 84/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1950 - accuracy: 0.9054 - val_loss: 0.1896 - val_accuracy: 0.9065\n",
      "Epoch 85/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1942 - accuracy: 0.9060 - val_loss: 0.1896 - val_accuracy: 0.9066\n",
      "Epoch 86/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1940 - accuracy: 0.9072 - val_loss: 0.1897 - val_accuracy: 0.9064\n",
      "Epoch 87/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1948 - accuracy: 0.9052 - val_loss: 0.1898 - val_accuracy: 0.9064\n",
      "Epoch 88/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1941 - accuracy: 0.9066 - val_loss: 0.1897 - val_accuracy: 0.9068\n",
      "Epoch 89/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1947 - accuracy: 0.9051 - val_loss: 0.1895 - val_accuracy: 0.9063\n",
      "Epoch 90/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1936 - accuracy: 0.9062 - val_loss: 0.1895 - val_accuracy: 0.9067\n",
      "Epoch 91/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1933 - accuracy: 0.9065 - val_loss: 0.1895 - val_accuracy: 0.9066\n",
      "Epoch 92/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1929 - accuracy: 0.9060 - val_loss: 0.1894 - val_accuracy: 0.9064\n",
      "Epoch 93/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1942 - accuracy: 0.9048 - val_loss: 0.1894 - val_accuracy: 0.9066\n",
      "Epoch 94/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1913 - accuracy: 0.9069 - val_loss: 0.1893 - val_accuracy: 0.9067\n",
      "Epoch 95/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1929 - accuracy: 0.9065 - val_loss: 0.1893 - val_accuracy: 0.9067\n",
      "Epoch 96/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1939 - accuracy: 0.9049 - val_loss: 0.1893 - val_accuracy: 0.9069\n",
      "Epoch 97/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1921 - accuracy: 0.9085 - val_loss: 0.1891 - val_accuracy: 0.9064\n",
      "Epoch 98/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1946 - accuracy: 0.9044 - val_loss: 0.1892 - val_accuracy: 0.9068\n",
      "Epoch 99/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1933 - accuracy: 0.9057 - val_loss: 0.1891 - val_accuracy: 0.9063\n",
      "Epoch 100/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1921 - accuracy: 0.9057 - val_loss: 0.1891 - val_accuracy: 0.9065\n",
      "Epoch 101/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1916 - accuracy: 0.9081 - val_loss: 0.1891 - val_accuracy: 0.9068\n",
      "Epoch 102/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1932 - accuracy: 0.9071 - val_loss: 0.1891 - val_accuracy: 0.9065\n",
      "Epoch 103/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1921 - accuracy: 0.9071 - val_loss: 0.1890 - val_accuracy: 0.9061\n",
      "Epoch 104/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1914 - accuracy: 0.9082 - val_loss: 0.1890 - val_accuracy: 0.9064\n",
      "Epoch 105/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1942 - accuracy: 0.9061 - val_loss: 0.1890 - val_accuracy: 0.9066\n",
      "Epoch 106/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1912 - accuracy: 0.9065 - val_loss: 0.1889 - val_accuracy: 0.9064\n",
      "Epoch 107/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1925 - accuracy: 0.9076 - val_loss: 0.1889 - val_accuracy: 0.9064\n",
      "Epoch 108/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1912 - accuracy: 0.9072 - val_loss: 0.1888 - val_accuracy: 0.9066\n",
      "Epoch 109/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1917 - accuracy: 0.9086 - val_loss: 0.1887 - val_accuracy: 0.9063\n",
      "Epoch 110/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1925 - accuracy: 0.9055 - val_loss: 0.1887 - val_accuracy: 0.9064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1916 - accuracy: 0.9053 - val_loss: 0.1888 - val_accuracy: 0.9064\n",
      "Epoch 112/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1908 - accuracy: 0.9067 - val_loss: 0.1887 - val_accuracy: 0.9068\n",
      "Epoch 113/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1913 - accuracy: 0.9075 - val_loss: 0.1887 - val_accuracy: 0.9065\n",
      "Epoch 114/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1906 - accuracy: 0.9071 - val_loss: 0.1887 - val_accuracy: 0.9065\n",
      "Epoch 115/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1928 - accuracy: 0.9062 - val_loss: 0.1887 - val_accuracy: 0.9068\n",
      "Epoch 116/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1907 - accuracy: 0.9065 - val_loss: 0.1887 - val_accuracy: 0.9069\n",
      "Epoch 117/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1916 - accuracy: 0.9060 - val_loss: 0.1886 - val_accuracy: 0.9068\n",
      "Epoch 118/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1909 - accuracy: 0.9076 - val_loss: 0.1886 - val_accuracy: 0.9069\n",
      "Epoch 119/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1904 - accuracy: 0.9073 - val_loss: 0.1887 - val_accuracy: 0.9070\n",
      "Epoch 120/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1901 - accuracy: 0.9078 - val_loss: 0.1886 - val_accuracy: 0.9070\n",
      "Epoch 121/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1907 - accuracy: 0.9064 - val_loss: 0.1886 - val_accuracy: 0.9071\n",
      "Epoch 122/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1910 - accuracy: 0.9068 - val_loss: 0.1886 - val_accuracy: 0.9070\n",
      "Epoch 123/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1902 - accuracy: 0.9077 - val_loss: 0.1886 - val_accuracy: 0.9070\n",
      "Epoch 124/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1905 - accuracy: 0.9079 - val_loss: 0.1885 - val_accuracy: 0.9070\n",
      "Epoch 125/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1890 - accuracy: 0.9058 - val_loss: 0.1886 - val_accuracy: 0.9073\n",
      "Epoch 126/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1913 - accuracy: 0.9069 - val_loss: 0.1885 - val_accuracy: 0.9073\n",
      "Epoch 127/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1924 - accuracy: 0.9051 - val_loss: 0.1886 - val_accuracy: 0.9069\n",
      "Epoch 128/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1904 - accuracy: 0.9070 - val_loss: 0.1885 - val_accuracy: 0.9073\n",
      "Epoch 129/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1895 - accuracy: 0.9058 - val_loss: 0.1886 - val_accuracy: 0.9076\n",
      "Epoch 130/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1901 - accuracy: 0.9084 - val_loss: 0.1885 - val_accuracy: 0.9073\n",
      "Epoch 131/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1908 - accuracy: 0.9063 - val_loss: 0.1884 - val_accuracy: 0.9070\n",
      "Epoch 132/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1902 - accuracy: 0.9061 - val_loss: 0.1885 - val_accuracy: 0.9077\n",
      "Epoch 133/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1894 - accuracy: 0.9059 - val_loss: 0.1885 - val_accuracy: 0.9071\n",
      "Epoch 134/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1897 - accuracy: 0.9084 - val_loss: 0.1884 - val_accuracy: 0.9072\n",
      "Epoch 135/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1890 - accuracy: 0.9072 - val_loss: 0.1883 - val_accuracy: 0.9077\n",
      "Epoch 136/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1893 - accuracy: 0.9071 - val_loss: 0.1884 - val_accuracy: 0.9077\n",
      "Epoch 137/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1881 - accuracy: 0.9081 - val_loss: 0.1884 - val_accuracy: 0.9074\n",
      "Epoch 138/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1890 - accuracy: 0.9064 - val_loss: 0.1883 - val_accuracy: 0.9074\n",
      "Epoch 139/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1908 - accuracy: 0.9084 - val_loss: 0.1883 - val_accuracy: 0.9077\n",
      "Epoch 140/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1892 - accuracy: 0.9067 - val_loss: 0.1884 - val_accuracy: 0.9074\n",
      "Epoch 141/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1900 - accuracy: 0.9064 - val_loss: 0.1883 - val_accuracy: 0.9076\n",
      "Epoch 142/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1908 - accuracy: 0.9067 - val_loss: 0.1884 - val_accuracy: 0.9077\n",
      "Epoch 143/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1894 - accuracy: 0.9060 - val_loss: 0.1883 - val_accuracy: 0.9074\n",
      "Epoch 144/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1891 - accuracy: 0.9063 - val_loss: 0.1882 - val_accuracy: 0.9075\n",
      "Epoch 145/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1906 - accuracy: 0.9066 - val_loss: 0.1881 - val_accuracy: 0.9073\n",
      "Epoch 146/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1897 - accuracy: 0.9066 - val_loss: 0.1881 - val_accuracy: 0.9072\n",
      "Epoch 147/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1883 - accuracy: 0.9088 - val_loss: 0.1881 - val_accuracy: 0.9073\n",
      "Epoch 148/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1885 - accuracy: 0.9104 - val_loss: 0.1880 - val_accuracy: 0.9073\n",
      "Epoch 149/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1899 - accuracy: 0.9078 - val_loss: 0.1879 - val_accuracy: 0.9073\n",
      "Epoch 150/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1886 - accuracy: 0.9069 - val_loss: 0.1880 - val_accuracy: 0.9073\n",
      "Epoch 151/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1887 - accuracy: 0.9073 - val_loss: 0.1880 - val_accuracy: 0.9075\n",
      "Epoch 152/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1873 - accuracy: 0.9079 - val_loss: 0.1880 - val_accuracy: 0.9073\n",
      "Epoch 153/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1888 - accuracy: 0.9065 - val_loss: 0.1881 - val_accuracy: 0.9072\n",
      "Epoch 154/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1888 - accuracy: 0.9078 - val_loss: 0.1880 - val_accuracy: 0.9072\n",
      "Epoch 155/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1885 - accuracy: 0.9090 - val_loss: 0.1880 - val_accuracy: 0.9073\n",
      "Epoch 156/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1881 - accuracy: 0.9076 - val_loss: 0.1879 - val_accuracy: 0.9074\n",
      "Epoch 157/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1890 - accuracy: 0.9072 - val_loss: 0.1878 - val_accuracy: 0.9073\n",
      "Epoch 158/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1882 - accuracy: 0.9089 - val_loss: 0.1877 - val_accuracy: 0.9077\n",
      "Epoch 159/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1888 - accuracy: 0.9064 - val_loss: 0.1878 - val_accuracy: 0.9076\n",
      "Epoch 160/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1896 - accuracy: 0.9080 - val_loss: 0.1878 - val_accuracy: 0.9075\n",
      "Epoch 161/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1884 - accuracy: 0.9072 - val_loss: 0.1879 - val_accuracy: 0.9077\n",
      "Epoch 162/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1871 - accuracy: 0.9084 - val_loss: 0.1879 - val_accuracy: 0.9077\n",
      "Epoch 163/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1889 - accuracy: 0.9073 - val_loss: 0.1878 - val_accuracy: 0.9079\n",
      "Epoch 164/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1879 - accuracy: 0.9086 - val_loss: 0.1877 - val_accuracy: 0.9074\n",
      "Epoch 165/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1892 - accuracy: 0.9068 - val_loss: 0.1877 - val_accuracy: 0.9077\n",
      "Epoch 166/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1889 - accuracy: 0.9065 - val_loss: 0.1878 - val_accuracy: 0.9078\n",
      "Epoch 167/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1881 - accuracy: 0.9066 - val_loss: 0.1878 - val_accuracy: 0.9079\n",
      "Epoch 168/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1878 - accuracy: 0.9097 - val_loss: 0.1877 - val_accuracy: 0.9081\n",
      "Epoch 169/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1881 - accuracy: 0.9093 - val_loss: 0.1877 - val_accuracy: 0.9080\n",
      "Epoch 170/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1892 - accuracy: 0.9080 - val_loss: 0.1876 - val_accuracy: 0.9081\n",
      "Epoch 171/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1873 - accuracy: 0.9083 - val_loss: 0.1876 - val_accuracy: 0.9081\n",
      "Epoch 172/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1881 - accuracy: 0.9086 - val_loss: 0.1876 - val_accuracy: 0.9083\n",
      "Epoch 173/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1882 - accuracy: 0.9086 - val_loss: 0.1876 - val_accuracy: 0.9079\n",
      "Epoch 174/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1877 - accuracy: 0.9080 - val_loss: 0.1875 - val_accuracy: 0.9080\n",
      "Epoch 175/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1875 - accuracy: 0.9070 - val_loss: 0.1875 - val_accuracy: 0.9079\n",
      "Epoch 176/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1857 - accuracy: 0.9081 - val_loss: 0.1875 - val_accuracy: 0.9083\n",
      "Epoch 177/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1890 - accuracy: 0.9081 - val_loss: 0.1875 - val_accuracy: 0.9080\n",
      "Epoch 178/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1885 - accuracy: 0.9071 - val_loss: 0.1875 - val_accuracy: 0.9082\n",
      "Epoch 179/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1860 - accuracy: 0.9104 - val_loss: 0.1874 - val_accuracy: 0.9086\n",
      "Epoch 180/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1865 - accuracy: 0.9072 - val_loss: 0.1874 - val_accuracy: 0.9082\n",
      "Epoch 181/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1868 - accuracy: 0.9083 - val_loss: 0.1875 - val_accuracy: 0.9082\n",
      "Epoch 182/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1877 - accuracy: 0.9090 - val_loss: 0.1874 - val_accuracy: 0.9086\n",
      "Epoch 183/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1859 - accuracy: 0.9095 - val_loss: 0.1873 - val_accuracy: 0.9084\n",
      "Epoch 184/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1867 - accuracy: 0.9086 - val_loss: 0.1873 - val_accuracy: 0.9082\n",
      "Epoch 185/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1873 - accuracy: 0.9101 - val_loss: 0.1873 - val_accuracy: 0.9086\n",
      "Epoch 186/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1868 - accuracy: 0.9075 - val_loss: 0.1873 - val_accuracy: 0.9081\n",
      "Epoch 187/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1847 - accuracy: 0.9101 - val_loss: 0.1873 - val_accuracy: 0.9085\n",
      "Epoch 188/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1874 - accuracy: 0.9091 - val_loss: 0.1871 - val_accuracy: 0.9084\n",
      "Epoch 189/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1867 - accuracy: 0.9080 - val_loss: 0.1871 - val_accuracy: 0.9082\n",
      "Epoch 190/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1865 - accuracy: 0.9086 - val_loss: 0.1870 - val_accuracy: 0.9083\n",
      "Epoch 191/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1864 - accuracy: 0.9070 - val_loss: 0.1872 - val_accuracy: 0.9084\n",
      "Epoch 192/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1866 - accuracy: 0.9084 - val_loss: 0.1871 - val_accuracy: 0.9084\n",
      "Epoch 193/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1871 - accuracy: 0.9084 - val_loss: 0.1871 - val_accuracy: 0.9084\n",
      "Epoch 194/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1863 - accuracy: 0.9086 - val_loss: 0.1871 - val_accuracy: 0.9084\n",
      "Epoch 195/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1850 - accuracy: 0.9089 - val_loss: 0.1871 - val_accuracy: 0.9086\n",
      "Epoch 196/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1882 - accuracy: 0.9085 - val_loss: 0.1871 - val_accuracy: 0.9082\n",
      "Epoch 197/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1865 - accuracy: 0.9087 - val_loss: 0.1871 - val_accuracy: 0.9085\n",
      "Epoch 198/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1855 - accuracy: 0.9094 - val_loss: 0.1870 - val_accuracy: 0.9088\n",
      "Epoch 199/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1867 - accuracy: 0.9076 - val_loss: 0.1870 - val_accuracy: 0.9085\n",
      "Epoch 200/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1876 - accuracy: 0.9086 - val_loss: 0.1868 - val_accuracy: 0.9085\n",
      "Epoch 201/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1874 - accuracy: 0.9094 - val_loss: 0.1868 - val_accuracy: 0.9084\n",
      "Epoch 202/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1876 - accuracy: 0.9077 - val_loss: 0.1869 - val_accuracy: 0.9086\n",
      "Epoch 203/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1861 - accuracy: 0.9092 - val_loss: 0.1868 - val_accuracy: 0.9083\n",
      "Epoch 204/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1856 - accuracy: 0.9097 - val_loss: 0.1868 - val_accuracy: 0.9083\n",
      "Epoch 205/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1867 - accuracy: 0.9088 - val_loss: 0.1869 - val_accuracy: 0.9080\n",
      "Epoch 206/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1855 - accuracy: 0.9094 - val_loss: 0.1868 - val_accuracy: 0.9081\n",
      "Epoch 207/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1851 - accuracy: 0.9093 - val_loss: 0.1868 - val_accuracy: 0.9081\n",
      "Epoch 208/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1867 - accuracy: 0.9099 - val_loss: 0.1867 - val_accuracy: 0.9080\n",
      "Epoch 209/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1846 - accuracy: 0.9097 - val_loss: 0.1868 - val_accuracy: 0.9082\n",
      "Epoch 210/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1858 - accuracy: 0.9108 - val_loss: 0.1868 - val_accuracy: 0.9083\n",
      "Epoch 211/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1871 - accuracy: 0.9092 - val_loss: 0.1868 - val_accuracy: 0.9081\n",
      "Epoch 212/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1858 - accuracy: 0.9113 - val_loss: 0.1868 - val_accuracy: 0.9081\n",
      "Epoch 213/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1850 - accuracy: 0.9094 - val_loss: 0.1866 - val_accuracy: 0.9083\n",
      "Epoch 214/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1857 - accuracy: 0.9079 - val_loss: 0.1867 - val_accuracy: 0.9076\n",
      "Epoch 215/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1860 - accuracy: 0.9086 - val_loss: 0.1867 - val_accuracy: 0.9080\n",
      "Epoch 216/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1870 - accuracy: 0.9088 - val_loss: 0.1867 - val_accuracy: 0.9080\n",
      "Epoch 217/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1866 - accuracy: 0.9074 - val_loss: 0.1868 - val_accuracy: 0.9077\n",
      "Epoch 218/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1852 - accuracy: 0.9088 - val_loss: 0.1867 - val_accuracy: 0.9079\n",
      "Epoch 219/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1851 - accuracy: 0.9100 - val_loss: 0.1866 - val_accuracy: 0.9086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 220/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1860 - accuracy: 0.9103 - val_loss: 0.1866 - val_accuracy: 0.9084\n",
      "Epoch 221/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1859 - accuracy: 0.9100 - val_loss: 0.1866 - val_accuracy: 0.9079\n",
      "Epoch 222/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1866 - accuracy: 0.9093 - val_loss: 0.1865 - val_accuracy: 0.9080\n",
      "Epoch 223/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1848 - accuracy: 0.9090 - val_loss: 0.1864 - val_accuracy: 0.9088\n",
      "Epoch 224/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1868 - accuracy: 0.9096 - val_loss: 0.1864 - val_accuracy: 0.9086\n",
      "Epoch 225/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1861 - accuracy: 0.9090 - val_loss: 0.1865 - val_accuracy: 0.9081\n",
      "Epoch 226/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1852 - accuracy: 0.9097 - val_loss: 0.1863 - val_accuracy: 0.9088\n",
      "Epoch 227/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1843 - accuracy: 0.9115 - val_loss: 0.1863 - val_accuracy: 0.9083\n",
      "Epoch 228/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1858 - accuracy: 0.9092 - val_loss: 0.1862 - val_accuracy: 0.9084\n",
      "Epoch 229/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1857 - accuracy: 0.9086 - val_loss: 0.1863 - val_accuracy: 0.9086\n",
      "Epoch 230/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1861 - accuracy: 0.9090 - val_loss: 0.1863 - val_accuracy: 0.9085\n",
      "Epoch 231/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1846 - accuracy: 0.9096 - val_loss: 0.1864 - val_accuracy: 0.9084\n",
      "Epoch 232/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1859 - accuracy: 0.9097 - val_loss: 0.1864 - val_accuracy: 0.9087\n",
      "Epoch 233/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1843 - accuracy: 0.9105 - val_loss: 0.1862 - val_accuracy: 0.9086\n",
      "Epoch 234/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1841 - accuracy: 0.9102 - val_loss: 0.1863 - val_accuracy: 0.9086\n",
      "Epoch 235/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1846 - accuracy: 0.9095 - val_loss: 0.1863 - val_accuracy: 0.9085\n",
      "Epoch 236/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1847 - accuracy: 0.9099 - val_loss: 0.1864 - val_accuracy: 0.9082\n",
      "Epoch 237/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1848 - accuracy: 0.9094 - val_loss: 0.1863 - val_accuracy: 0.9084\n",
      "Epoch 238/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1839 - accuracy: 0.9102 - val_loss: 0.1863 - val_accuracy: 0.9082\n",
      "Epoch 239/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1846 - accuracy: 0.9116 - val_loss: 0.1863 - val_accuracy: 0.9086\n",
      "Epoch 240/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1864 - accuracy: 0.9084 - val_loss: 0.1862 - val_accuracy: 0.9085\n",
      "Epoch 241/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1864 - accuracy: 0.9088 - val_loss: 0.1863 - val_accuracy: 0.9085\n",
      "Epoch 242/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1857 - accuracy: 0.9092 - val_loss: 0.1862 - val_accuracy: 0.9086\n",
      "Epoch 243/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1836 - accuracy: 0.9104 - val_loss: 0.1862 - val_accuracy: 0.9081\n",
      "Epoch 244/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1839 - accuracy: 0.9099 - val_loss: 0.1860 - val_accuracy: 0.9083\n",
      "Epoch 245/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1845 - accuracy: 0.9108 - val_loss: 0.1859 - val_accuracy: 0.9081\n",
      "Epoch 246/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1842 - accuracy: 0.9093 - val_loss: 0.1861 - val_accuracy: 0.9086\n",
      "Epoch 247/800\n",
      "28831/28831 [==============================] - 1s 19us/step - loss: 0.1841 - accuracy: 0.9110 - val_loss: 0.1860 - val_accuracy: 0.9088\n",
      "Epoch 248/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1840 - accuracy: 0.9100 - val_loss: 0.1860 - val_accuracy: 0.9088\n",
      "Epoch 249/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1837 - accuracy: 0.9103 - val_loss: 0.1860 - val_accuracy: 0.9087\n",
      "Epoch 250/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1849 - accuracy: 0.9115 - val_loss: 0.1859 - val_accuracy: 0.9088\n",
      "Epoch 251/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1852 - accuracy: 0.9105 - val_loss: 0.1860 - val_accuracy: 0.9086\n",
      "Epoch 252/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1841 - accuracy: 0.9115 - val_loss: 0.1860 - val_accuracy: 0.9086\n",
      "Epoch 253/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1854 - accuracy: 0.9098 - val_loss: 0.1860 - val_accuracy: 0.9081\n",
      "Epoch 254/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1847 - accuracy: 0.9105 - val_loss: 0.1860 - val_accuracy: 0.9081\n",
      "Epoch 255/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1853 - accuracy: 0.9097 - val_loss: 0.1860 - val_accuracy: 0.9082\n",
      "Epoch 256/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1857 - accuracy: 0.9101 - val_loss: 0.1860 - val_accuracy: 0.9085\n",
      "Epoch 257/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1834 - accuracy: 0.9115 - val_loss: 0.1858 - val_accuracy: 0.9094\n",
      "Epoch 258/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1850 - accuracy: 0.9107 - val_loss: 0.1857 - val_accuracy: 0.9090\n",
      "Epoch 259/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1847 - accuracy: 0.9105 - val_loss: 0.1857 - val_accuracy: 0.9091\n",
      "Epoch 260/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1854 - accuracy: 0.9087 - val_loss: 0.1858 - val_accuracy: 0.9087\n",
      "Epoch 261/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1847 - accuracy: 0.9099 - val_loss: 0.1857 - val_accuracy: 0.9090\n",
      "Epoch 262/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1837 - accuracy: 0.9105 - val_loss: 0.1857 - val_accuracy: 0.9088\n",
      "Epoch 263/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1849 - accuracy: 0.9086 - val_loss: 0.1857 - val_accuracy: 0.9086\n",
      "Epoch 264/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1847 - accuracy: 0.9085 - val_loss: 0.1858 - val_accuracy: 0.9086\n",
      "Epoch 265/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1834 - accuracy: 0.9106 - val_loss: 0.1857 - val_accuracy: 0.9090\n",
      "Epoch 266/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1832 - accuracy: 0.9122 - val_loss: 0.1857 - val_accuracy: 0.9091\n",
      "Epoch 267/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1841 - accuracy: 0.9103 - val_loss: 0.1858 - val_accuracy: 0.9094\n",
      "Epoch 268/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1846 - accuracy: 0.9092 - val_loss: 0.1858 - val_accuracy: 0.9087\n",
      "Epoch 269/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1830 - accuracy: 0.9107 - val_loss: 0.1860 - val_accuracy: 0.9086\n",
      "Epoch 270/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1860 - accuracy: 0.9103 - val_loss: 0.1858 - val_accuracy: 0.9084\n",
      "Epoch 271/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1830 - accuracy: 0.9098 - val_loss: 0.1858 - val_accuracy: 0.9082\n",
      "Epoch 272/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1826 - accuracy: 0.9126 - val_loss: 0.1858 - val_accuracy: 0.9093\n",
      "Epoch 273/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1831 - accuracy: 0.9115 - val_loss: 0.1858 - val_accuracy: 0.9090\n",
      "Epoch 274/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1843 - accuracy: 0.9113 - val_loss: 0.1859 - val_accuracy: 0.9085\n",
      "Epoch 275/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1831 - accuracy: 0.9110 - val_loss: 0.1858 - val_accuracy: 0.9086\n",
      "Epoch 276/800\n",
      "28831/28831 [==============================] - 0s 16us/step - loss: 0.1830 - accuracy: 0.9105 - val_loss: 0.1859 - val_accuracy: 0.9084\n",
      "Epoch 277/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1832 - accuracy: 0.9103 - val_loss: 0.1859 - val_accuracy: 0.9088\n",
      "Epoch 278/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1830 - accuracy: 0.9113 - val_loss: 0.1858 - val_accuracy: 0.9086\n",
      "Epoch 279/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1829 - accuracy: 0.9110 - val_loss: 0.1858 - val_accuracy: 0.9085\n",
      "Epoch 280/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1840 - accuracy: 0.9103 - val_loss: 0.1858 - val_accuracy: 0.9084\n",
      "Epoch 281/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1837 - accuracy: 0.9114 - val_loss: 0.1857 - val_accuracy: 0.9082\n",
      "Epoch 282/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1835 - accuracy: 0.9105 - val_loss: 0.1857 - val_accuracy: 0.9084\n",
      "Epoch 283/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1838 - accuracy: 0.9112 - val_loss: 0.1857 - val_accuracy: 0.9084\n",
      "Epoch 284/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1837 - accuracy: 0.9109 - val_loss: 0.1857 - val_accuracy: 0.9084\n",
      "Epoch 285/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1846 - accuracy: 0.9121 - val_loss: 0.1857 - val_accuracy: 0.9084\n",
      "Epoch 286/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1833 - accuracy: 0.9113 - val_loss: 0.1856 - val_accuracy: 0.9082\n",
      "Epoch 287/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1830 - accuracy: 0.9105 - val_loss: 0.1857 - val_accuracy: 0.9084\n",
      "Epoch 288/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1823 - accuracy: 0.9121 - val_loss: 0.1857 - val_accuracy: 0.9085\n",
      "Epoch 289/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1849 - accuracy: 0.9091 - val_loss: 0.1856 - val_accuracy: 0.9084\n",
      "Epoch 290/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1831 - accuracy: 0.9120 - val_loss: 0.1856 - val_accuracy: 0.9088\n",
      "Epoch 291/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1830 - accuracy: 0.9109 - val_loss: 0.1857 - val_accuracy: 0.9086\n",
      "Epoch 292/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1827 - accuracy: 0.9106 - val_loss: 0.1856 - val_accuracy: 0.9088\n",
      "Epoch 293/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1832 - accuracy: 0.9116 - val_loss: 0.1856 - val_accuracy: 0.9088\n",
      "Epoch 294/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1840 - accuracy: 0.9100 - val_loss: 0.1855 - val_accuracy: 0.9087\n",
      "Epoch 295/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1842 - accuracy: 0.9107 - val_loss: 0.1854 - val_accuracy: 0.9089\n",
      "Epoch 296/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1817 - accuracy: 0.9114 - val_loss: 0.1854 - val_accuracy: 0.9088\n",
      "Epoch 297/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1833 - accuracy: 0.9101 - val_loss: 0.1856 - val_accuracy: 0.9088\n",
      "Epoch 298/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1841 - accuracy: 0.9112 - val_loss: 0.1855 - val_accuracy: 0.9086\n",
      "Epoch 299/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1832 - accuracy: 0.9105 - val_loss: 0.1855 - val_accuracy: 0.9085\n",
      "Epoch 300/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1826 - accuracy: 0.9117 - val_loss: 0.1855 - val_accuracy: 0.9089\n",
      "Epoch 301/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1827 - accuracy: 0.9124 - val_loss: 0.1855 - val_accuracy: 0.9086\n",
      "Epoch 302/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1829 - accuracy: 0.9120 - val_loss: 0.1855 - val_accuracy: 0.9088\n",
      "Epoch 303/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1829 - accuracy: 0.9105 - val_loss: 0.1854 - val_accuracy: 0.9089\n",
      "Epoch 304/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1826 - accuracy: 0.9114 - val_loss: 0.1853 - val_accuracy: 0.9088\n",
      "Epoch 305/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1820 - accuracy: 0.9110 - val_loss: 0.1853 - val_accuracy: 0.9089\n",
      "Epoch 306/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1812 - accuracy: 0.9116 - val_loss: 0.1852 - val_accuracy: 0.9085\n",
      "Epoch 307/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1845 - accuracy: 0.9108 - val_loss: 0.1852 - val_accuracy: 0.9084\n",
      "Epoch 308/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1826 - accuracy: 0.9120 - val_loss: 0.1852 - val_accuracy: 0.9083\n",
      "Epoch 309/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1833 - accuracy: 0.9101 - val_loss: 0.1852 - val_accuracy: 0.9086\n",
      "Epoch 310/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1827 - accuracy: 0.9116 - val_loss: 0.1852 - val_accuracy: 0.9086\n",
      "Epoch 311/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1838 - accuracy: 0.9094 - val_loss: 0.1852 - val_accuracy: 0.9086\n",
      "Epoch 312/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1846 - accuracy: 0.9107 - val_loss: 0.1853 - val_accuracy: 0.9086\n",
      "Epoch 313/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1834 - accuracy: 0.9119 - val_loss: 0.1852 - val_accuracy: 0.9081\n",
      "Epoch 314/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1833 - accuracy: 0.9119 - val_loss: 0.1853 - val_accuracy: 0.9081\n",
      "Epoch 315/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1832 - accuracy: 0.9100 - val_loss: 0.1854 - val_accuracy: 0.9086\n",
      "Epoch 316/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1820 - accuracy: 0.9112 - val_loss: 0.1853 - val_accuracy: 0.9084\n",
      "Epoch 317/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1823 - accuracy: 0.9117 - val_loss: 0.1851 - val_accuracy: 0.9082\n",
      "Epoch 318/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1820 - accuracy: 0.9113 - val_loss: 0.1852 - val_accuracy: 0.9085\n",
      "Epoch 319/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1826 - accuracy: 0.9120 - val_loss: 0.1853 - val_accuracy: 0.9081\n",
      "Epoch 320/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1821 - accuracy: 0.9119 - val_loss: 0.1852 - val_accuracy: 0.9081\n",
      "Epoch 321/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1814 - accuracy: 0.9110 - val_loss: 0.1852 - val_accuracy: 0.9086\n",
      "Epoch 322/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1832 - accuracy: 0.9118 - val_loss: 0.1852 - val_accuracy: 0.9081\n",
      "Epoch 323/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1843 - accuracy: 0.9105 - val_loss: 0.1852 - val_accuracy: 0.9081\n",
      "Epoch 324/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1829 - accuracy: 0.9106 - val_loss: 0.1852 - val_accuracy: 0.9079\n",
      "Epoch 325/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1809 - accuracy: 0.9125 - val_loss: 0.1851 - val_accuracy: 0.9081\n",
      "Epoch 326/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1818 - accuracy: 0.9099 - val_loss: 0.1850 - val_accuracy: 0.9083\n",
      "Epoch 327/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1827 - accuracy: 0.9106 - val_loss: 0.1850 - val_accuracy: 0.9083\n",
      "Epoch 328/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1819 - accuracy: 0.9107 - val_loss: 0.1851 - val_accuracy: 0.9077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 329/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1825 - accuracy: 0.9108 - val_loss: 0.1851 - val_accuracy: 0.9082\n",
      "Epoch 330/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1819 - accuracy: 0.9124 - val_loss: 0.1850 - val_accuracy: 0.9082\n",
      "Epoch 331/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1834 - accuracy: 0.9112 - val_loss: 0.1851 - val_accuracy: 0.9079\n",
      "Epoch 332/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1835 - accuracy: 0.9130 - val_loss: 0.1850 - val_accuracy: 0.9086\n",
      "Epoch 333/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1816 - accuracy: 0.9126 - val_loss: 0.1850 - val_accuracy: 0.9078\n",
      "Epoch 334/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1816 - accuracy: 0.9117 - val_loss: 0.1849 - val_accuracy: 0.9083\n",
      "Epoch 335/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1832 - accuracy: 0.9111 - val_loss: 0.1850 - val_accuracy: 0.9077\n",
      "Epoch 336/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1814 - accuracy: 0.9124 - val_loss: 0.1850 - val_accuracy: 0.9083\n",
      "Epoch 337/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1824 - accuracy: 0.9115 - val_loss: 0.1850 - val_accuracy: 0.9083\n",
      "Epoch 338/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1832 - accuracy: 0.9116 - val_loss: 0.1851 - val_accuracy: 0.9086\n",
      "Epoch 339/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1813 - accuracy: 0.9134 - val_loss: 0.1851 - val_accuracy: 0.9086\n",
      "Epoch 340/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1823 - accuracy: 0.9114 - val_loss: 0.1850 - val_accuracy: 0.9086\n",
      "Epoch 341/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1818 - accuracy: 0.9115 - val_loss: 0.1849 - val_accuracy: 0.9084\n",
      "Epoch 342/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1833 - accuracy: 0.9119 - val_loss: 0.1849 - val_accuracy: 0.9087\n",
      "Epoch 343/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1811 - accuracy: 0.9123 - val_loss: 0.1849 - val_accuracy: 0.9084\n",
      "Epoch 344/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1828 - accuracy: 0.9118 - val_loss: 0.1849 - val_accuracy: 0.9081\n",
      "Epoch 345/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1823 - accuracy: 0.9125 - val_loss: 0.1848 - val_accuracy: 0.9086\n",
      "Epoch 346/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1819 - accuracy: 0.9122 - val_loss: 0.1849 - val_accuracy: 0.9081\n",
      "Epoch 347/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1819 - accuracy: 0.9127 - val_loss: 0.1849 - val_accuracy: 0.9081\n",
      "Epoch 348/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1817 - accuracy: 0.9117 - val_loss: 0.1849 - val_accuracy: 0.9082\n",
      "Epoch 349/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1806 - accuracy: 0.9108 - val_loss: 0.1849 - val_accuracy: 0.9081\n",
      "Epoch 350/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1824 - accuracy: 0.9113 - val_loss: 0.1849 - val_accuracy: 0.9081\n",
      "Epoch 351/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1817 - accuracy: 0.9109 - val_loss: 0.1849 - val_accuracy: 0.9082\n",
      "Epoch 352/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1818 - accuracy: 0.9121 - val_loss: 0.1848 - val_accuracy: 0.9082\n",
      "Epoch 353/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1805 - accuracy: 0.9130 - val_loss: 0.1848 - val_accuracy: 0.9085\n",
      "Epoch 354/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1815 - accuracy: 0.9117 - val_loss: 0.1849 - val_accuracy: 0.9086\n",
      "Epoch 355/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1821 - accuracy: 0.9114 - val_loss: 0.1849 - val_accuracy: 0.9083\n",
      "Epoch 356/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1820 - accuracy: 0.9114 - val_loss: 0.1849 - val_accuracy: 0.9081\n",
      "Epoch 357/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1826 - accuracy: 0.9105 - val_loss: 0.1848 - val_accuracy: 0.9081\n",
      "Epoch 358/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1823 - accuracy: 0.9127 - val_loss: 0.1849 - val_accuracy: 0.9086\n",
      "Epoch 359/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1827 - accuracy: 0.9111 - val_loss: 0.1849 - val_accuracy: 0.9081\n",
      "Epoch 360/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1821 - accuracy: 0.9125 - val_loss: 0.1849 - val_accuracy: 0.9082\n",
      "Epoch 361/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1818 - accuracy: 0.9129 - val_loss: 0.1849 - val_accuracy: 0.9087\n",
      "Epoch 362/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1817 - accuracy: 0.9114 - val_loss: 0.1849 - val_accuracy: 0.9081\n",
      "Epoch 363/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1823 - accuracy: 0.9117 - val_loss: 0.1849 - val_accuracy: 0.9082\n",
      "Epoch 364/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1826 - accuracy: 0.9120 - val_loss: 0.1850 - val_accuracy: 0.9080\n",
      "Epoch 365/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1822 - accuracy: 0.9118 - val_loss: 0.1851 - val_accuracy: 0.9084\n",
      "Epoch 366/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1821 - accuracy: 0.9126 - val_loss: 0.1850 - val_accuracy: 0.9082\n",
      "Epoch 367/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1829 - accuracy: 0.9110 - val_loss: 0.1850 - val_accuracy: 0.9083\n",
      "Epoch 368/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1817 - accuracy: 0.9125 - val_loss: 0.1851 - val_accuracy: 0.9089\n",
      "Epoch 369/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1813 - accuracy: 0.9125 - val_loss: 0.1851 - val_accuracy: 0.9087\n",
      "Epoch 370/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1816 - accuracy: 0.9124 - val_loss: 0.1852 - val_accuracy: 0.9087\n",
      "Epoch 371/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1817 - accuracy: 0.9108 - val_loss: 0.1850 - val_accuracy: 0.9087\n",
      "Epoch 372/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1815 - accuracy: 0.9121 - val_loss: 0.1850 - val_accuracy: 0.9083\n",
      "Epoch 373/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1831 - accuracy: 0.9111 - val_loss: 0.1851 - val_accuracy: 0.9081\n",
      "Epoch 374/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1807 - accuracy: 0.9124 - val_loss: 0.1851 - val_accuracy: 0.9081\n",
      "Epoch 375/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1823 - accuracy: 0.9128 - val_loss: 0.1850 - val_accuracy: 0.9083\n",
      "Epoch 376/800\n",
      "28831/28831 [==============================] - 1s 19us/step - loss: 0.1823 - accuracy: 0.9113 - val_loss: 0.1850 - val_accuracy: 0.9079\n",
      "Epoch 377/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1822 - accuracy: 0.9110 - val_loss: 0.1849 - val_accuracy: 0.9082\n",
      "Epoch 378/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1815 - accuracy: 0.9134 - val_loss: 0.1848 - val_accuracy: 0.9087\n",
      "Epoch 379/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1810 - accuracy: 0.9120 - val_loss: 0.1848 - val_accuracy: 0.9082\n",
      "Epoch 380/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1818 - accuracy: 0.9118 - val_loss: 0.1849 - val_accuracy: 0.9088\n",
      "Epoch 381/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1819 - accuracy: 0.9120 - val_loss: 0.1849 - val_accuracy: 0.9094\n",
      "Epoch 382/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1807 - accuracy: 0.9114 - val_loss: 0.1848 - val_accuracy: 0.9090\n",
      "Epoch 383/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1814 - accuracy: 0.9111 - val_loss: 0.1849 - val_accuracy: 0.9084\n",
      "Epoch 384/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1811 - accuracy: 0.9101 - val_loss: 0.1850 - val_accuracy: 0.9090\n",
      "Epoch 385/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1802 - accuracy: 0.9120 - val_loss: 0.1850 - val_accuracy: 0.9091\n",
      "Epoch 386/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1830 - accuracy: 0.9115 - val_loss: 0.1851 - val_accuracy: 0.9087\n",
      "Epoch 387/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1827 - accuracy: 0.9107 - val_loss: 0.1848 - val_accuracy: 0.9090\n",
      "Epoch 388/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1819 - accuracy: 0.9124 - val_loss: 0.1849 - val_accuracy: 0.9095\n",
      "Epoch 389/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1812 - accuracy: 0.9121 - val_loss: 0.1849 - val_accuracy: 0.9094\n",
      "Epoch 390/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1813 - accuracy: 0.9109 - val_loss: 0.1849 - val_accuracy: 0.9089\n",
      "Epoch 391/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1816 - accuracy: 0.9103 - val_loss: 0.1849 - val_accuracy: 0.9090\n",
      "Epoch 392/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1827 - accuracy: 0.9104 - val_loss: 0.1850 - val_accuracy: 0.9090\n",
      "Epoch 393/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1819 - accuracy: 0.9111 - val_loss: 0.1852 - val_accuracy: 0.9091\n",
      "Epoch 394/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1817 - accuracy: 0.9112 - val_loss: 0.1851 - val_accuracy: 0.9089\n",
      "Epoch 395/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1808 - accuracy: 0.9126 - val_loss: 0.1851 - val_accuracy: 0.9093\n",
      "Epoch 396/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1820 - accuracy: 0.9128 - val_loss: 0.1850 - val_accuracy: 0.9092\n",
      "Epoch 397/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1811 - accuracy: 0.9136 - val_loss: 0.1850 - val_accuracy: 0.9088\n",
      "Epoch 398/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1818 - accuracy: 0.9126 - val_loss: 0.1850 - val_accuracy: 0.9090\n",
      "Epoch 399/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1818 - accuracy: 0.9122 - val_loss: 0.1850 - val_accuracy: 0.9091\n",
      "Epoch 400/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1817 - accuracy: 0.9119 - val_loss: 0.1849 - val_accuracy: 0.9094\n",
      "Epoch 401/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1821 - accuracy: 0.9112 - val_loss: 0.1849 - val_accuracy: 0.9094\n",
      "Epoch 402/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1805 - accuracy: 0.9116 - val_loss: 0.1849 - val_accuracy: 0.9090\n",
      "Epoch 403/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1804 - accuracy: 0.9126 - val_loss: 0.1849 - val_accuracy: 0.9094\n",
      "Epoch 404/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1815 - accuracy: 0.9125 - val_loss: 0.1849 - val_accuracy: 0.9093\n",
      "Epoch 405/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1800 - accuracy: 0.9099 - val_loss: 0.1850 - val_accuracy: 0.9090\n",
      "Epoch 406/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1808 - accuracy: 0.9118 - val_loss: 0.1851 - val_accuracy: 0.9089\n",
      "Epoch 407/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1809 - accuracy: 0.9109 - val_loss: 0.1850 - val_accuracy: 0.9093\n",
      "Epoch 408/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1805 - accuracy: 0.9126 - val_loss: 0.1850 - val_accuracy: 0.9096\n",
      "Epoch 409/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1818 - accuracy: 0.9115 - val_loss: 0.1849 - val_accuracy: 0.9093\n",
      "Epoch 410/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1805 - accuracy: 0.9126 - val_loss: 0.1849 - val_accuracy: 0.9093\n",
      "Epoch 411/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1823 - accuracy: 0.9125 - val_loss: 0.1848 - val_accuracy: 0.9090\n",
      "Epoch 412/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1797 - accuracy: 0.9128 - val_loss: 0.1849 - val_accuracy: 0.9094\n",
      "Epoch 413/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1814 - accuracy: 0.9115 - val_loss: 0.1848 - val_accuracy: 0.9093\n",
      "Epoch 414/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1816 - accuracy: 0.9114 - val_loss: 0.1849 - val_accuracy: 0.9083\n",
      "Epoch 415/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1806 - accuracy: 0.9128 - val_loss: 0.1849 - val_accuracy: 0.9089\n",
      "Epoch 416/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1793 - accuracy: 0.9130 - val_loss: 0.1849 - val_accuracy: 0.9093\n",
      "Epoch 417/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1821 - accuracy: 0.9124 - val_loss: 0.1850 - val_accuracy: 0.9089\n",
      "Epoch 418/800\n",
      "28831/28831 [==============================] - 0s 16us/step - loss: 0.1816 - accuracy: 0.9108 - val_loss: 0.1850 - val_accuracy: 0.9091\n",
      "Epoch 419/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1805 - accuracy: 0.9130 - val_loss: 0.1850 - val_accuracy: 0.9088\n",
      "Epoch 420/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1812 - accuracy: 0.9119 - val_loss: 0.1849 - val_accuracy: 0.9089\n",
      "Epoch 421/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1803 - accuracy: 0.9131 - val_loss: 0.1850 - val_accuracy: 0.9089\n",
      "Epoch 422/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1806 - accuracy: 0.9116 - val_loss: 0.1849 - val_accuracy: 0.9093\n",
      "Epoch 423/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1800 - accuracy: 0.9117 - val_loss: 0.1850 - val_accuracy: 0.9090\n",
      "Epoch 424/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1798 - accuracy: 0.9139 - val_loss: 0.1848 - val_accuracy: 0.9092\n",
      "Epoch 425/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1813 - accuracy: 0.9132 - val_loss: 0.1850 - val_accuracy: 0.9094\n",
      "Epoch 426/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1811 - accuracy: 0.9132 - val_loss: 0.1850 - val_accuracy: 0.9090\n",
      "Epoch 427/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1812 - accuracy: 0.9116 - val_loss: 0.1851 - val_accuracy: 0.9095\n",
      "Epoch 428/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1813 - accuracy: 0.9121 - val_loss: 0.1851 - val_accuracy: 0.9093\n",
      "Epoch 429/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1809 - accuracy: 0.9122 - val_loss: 0.1851 - val_accuracy: 0.9091\n",
      "Epoch 430/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1807 - accuracy: 0.9122 - val_loss: 0.1852 - val_accuracy: 0.9090\n",
      "Epoch 431/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1801 - accuracy: 0.9121 - val_loss: 0.1852 - val_accuracy: 0.9093\n",
      "Epoch 432/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1806 - accuracy: 0.9139 - val_loss: 0.1853 - val_accuracy: 0.9096\n",
      "Epoch 433/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1810 - accuracy: 0.9114 - val_loss: 0.1852 - val_accuracy: 0.9095\n",
      "Epoch 434/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1808 - accuracy: 0.9125 - val_loss: 0.1850 - val_accuracy: 0.9091\n",
      "Epoch 435/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1806 - accuracy: 0.9123 - val_loss: 0.1851 - val_accuracy: 0.9093\n",
      "Epoch 436/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1820 - accuracy: 0.9110 - val_loss: 0.1851 - val_accuracy: 0.9091\n",
      "Epoch 437/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1805 - accuracy: 0.9118 - val_loss: 0.1852 - val_accuracy: 0.9091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 438/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1803 - accuracy: 0.9112 - val_loss: 0.1851 - val_accuracy: 0.9093\n",
      "Epoch 439/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1802 - accuracy: 0.9118 - val_loss: 0.1851 - val_accuracy: 0.9094\n",
      "Epoch 440/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1789 - accuracy: 0.9111 - val_loss: 0.1850 - val_accuracy: 0.9094\n",
      "Epoch 441/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1803 - accuracy: 0.9141 - val_loss: 0.1850 - val_accuracy: 0.9095\n",
      "Epoch 442/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1810 - accuracy: 0.9133 - val_loss: 0.1850 - val_accuracy: 0.9101\n",
      "Epoch 443/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1801 - accuracy: 0.9130 - val_loss: 0.1850 - val_accuracy: 0.9102\n",
      "Epoch 444/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1807 - accuracy: 0.9131 - val_loss: 0.1850 - val_accuracy: 0.9097\n",
      "Epoch 445/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1814 - accuracy: 0.9121 - val_loss: 0.1850 - val_accuracy: 0.9092\n",
      "Epoch 446/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1791 - accuracy: 0.9127 - val_loss: 0.1849 - val_accuracy: 0.9096\n",
      "Epoch 447/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1805 - accuracy: 0.9120 - val_loss: 0.1850 - val_accuracy: 0.9092\n",
      "Epoch 448/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1804 - accuracy: 0.9114 - val_loss: 0.1850 - val_accuracy: 0.9097\n",
      "Epoch 449/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1822 - accuracy: 0.9119 - val_loss: 0.1851 - val_accuracy: 0.9097\n",
      "Epoch 450/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1800 - accuracy: 0.9132 - val_loss: 0.1850 - val_accuracy: 0.9094\n",
      "Epoch 451/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1809 - accuracy: 0.9125 - val_loss: 0.1850 - val_accuracy: 0.9098\n",
      "Epoch 452/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1815 - accuracy: 0.9125 - val_loss: 0.1849 - val_accuracy: 0.9094\n",
      "Epoch 453/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1792 - accuracy: 0.9125 - val_loss: 0.1850 - val_accuracy: 0.9099\n",
      "Epoch 454/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1810 - accuracy: 0.9115 - val_loss: 0.1849 - val_accuracy: 0.9094\n",
      "Epoch 455/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1808 - accuracy: 0.9142 - val_loss: 0.1849 - val_accuracy: 0.9103\n",
      "Epoch 456/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1802 - accuracy: 0.9139 - val_loss: 0.1850 - val_accuracy: 0.9103\n",
      "Epoch 457/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1805 - accuracy: 0.9117 - val_loss: 0.1850 - val_accuracy: 0.9103\n",
      "Epoch 458/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1801 - accuracy: 0.9137 - val_loss: 0.1850 - val_accuracy: 0.9100\n",
      "Epoch 459/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1806 - accuracy: 0.9120 - val_loss: 0.1850 - val_accuracy: 0.9104\n",
      "Epoch 460/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1812 - accuracy: 0.9136 - val_loss: 0.1849 - val_accuracy: 0.9103\n",
      "Epoch 461/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1796 - accuracy: 0.9131 - val_loss: 0.1850 - val_accuracy: 0.9105\n",
      "Epoch 462/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1808 - accuracy: 0.9128 - val_loss: 0.1849 - val_accuracy: 0.9105\n",
      "Epoch 463/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1811 - accuracy: 0.9135 - val_loss: 0.1850 - val_accuracy: 0.9107\n",
      "Epoch 464/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1823 - accuracy: 0.9125 - val_loss: 0.1850 - val_accuracy: 0.9100\n",
      "Epoch 465/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1808 - accuracy: 0.9124 - val_loss: 0.1851 - val_accuracy: 0.9103\n",
      "Epoch 466/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1814 - accuracy: 0.9129 - val_loss: 0.1849 - val_accuracy: 0.9103\n",
      "Epoch 467/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1806 - accuracy: 0.9133 - val_loss: 0.1849 - val_accuracy: 0.9107\n",
      "Epoch 468/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1788 - accuracy: 0.9134 - val_loss: 0.1849 - val_accuracy: 0.9107\n",
      "Epoch 469/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1816 - accuracy: 0.9122 - val_loss: 0.1849 - val_accuracy: 0.9103\n",
      "Epoch 470/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1808 - accuracy: 0.9116 - val_loss: 0.1848 - val_accuracy: 0.9107\n",
      "Epoch 471/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1815 - accuracy: 0.9126 - val_loss: 0.1848 - val_accuracy: 0.9103\n",
      "Epoch 472/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1800 - accuracy: 0.9129 - val_loss: 0.1848 - val_accuracy: 0.9103\n",
      "Epoch 473/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1810 - accuracy: 0.9123 - val_loss: 0.1848 - val_accuracy: 0.9102\n",
      "Epoch 474/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1807 - accuracy: 0.9141 - val_loss: 0.1847 - val_accuracy: 0.9102\n",
      "Epoch 475/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1809 - accuracy: 0.9135 - val_loss: 0.1846 - val_accuracy: 0.9098\n",
      "Epoch 476/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1807 - accuracy: 0.9129 - val_loss: 0.1847 - val_accuracy: 0.9106\n",
      "Epoch 477/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1798 - accuracy: 0.9141 - val_loss: 0.1848 - val_accuracy: 0.9103\n",
      "Epoch 478/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1810 - accuracy: 0.9127 - val_loss: 0.1848 - val_accuracy: 0.9103\n",
      "Epoch 479/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1810 - accuracy: 0.9129 - val_loss: 0.1849 - val_accuracy: 0.9104\n",
      "Epoch 480/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1799 - accuracy: 0.9134 - val_loss: 0.1848 - val_accuracy: 0.9107\n",
      "Epoch 481/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1810 - accuracy: 0.9125 - val_loss: 0.1848 - val_accuracy: 0.9107\n",
      "Epoch 482/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1805 - accuracy: 0.9143 - val_loss: 0.1849 - val_accuracy: 0.9109\n",
      "Epoch 483/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1797 - accuracy: 0.9135 - val_loss: 0.1849 - val_accuracy: 0.9111\n",
      "Epoch 484/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1795 - accuracy: 0.9129 - val_loss: 0.1849 - val_accuracy: 0.9107\n",
      "Epoch 485/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1809 - accuracy: 0.9112 - val_loss: 0.1848 - val_accuracy: 0.9108\n",
      "Epoch 486/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1795 - accuracy: 0.9130 - val_loss: 0.1849 - val_accuracy: 0.9108\n",
      "Epoch 487/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1810 - accuracy: 0.9118 - val_loss: 0.1847 - val_accuracy: 0.9108\n",
      "Epoch 488/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1808 - accuracy: 0.9140 - val_loss: 0.1847 - val_accuracy: 0.9111\n",
      "Epoch 489/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1804 - accuracy: 0.9115 - val_loss: 0.1848 - val_accuracy: 0.9103\n",
      "Epoch 490/800\n",
      "28831/28831 [==============================] - 1s 19us/step - loss: 0.1818 - accuracy: 0.9126 - val_loss: 0.1849 - val_accuracy: 0.9105\n",
      "Epoch 491/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1803 - accuracy: 0.9121 - val_loss: 0.1848 - val_accuracy: 0.9107\n",
      "Epoch 492/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1809 - accuracy: 0.9131 - val_loss: 0.1848 - val_accuracy: 0.9104\n",
      "Epoch 493/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1809 - accuracy: 0.9137 - val_loss: 0.1847 - val_accuracy: 0.9107\n",
      "Epoch 494/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1800 - accuracy: 0.9135 - val_loss: 0.1847 - val_accuracy: 0.9107\n",
      "Epoch 495/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1810 - accuracy: 0.9137 - val_loss: 0.1848 - val_accuracy: 0.9105\n",
      "Epoch 496/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1798 - accuracy: 0.9126 - val_loss: 0.1849 - val_accuracy: 0.9104\n",
      "Epoch 497/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1801 - accuracy: 0.9123 - val_loss: 0.1848 - val_accuracy: 0.9107\n",
      "Epoch 498/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1801 - accuracy: 0.9126 - val_loss: 0.1847 - val_accuracy: 0.9107\n",
      "Epoch 499/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1784 - accuracy: 0.9136 - val_loss: 0.1848 - val_accuracy: 0.9105\n",
      "Epoch 500/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1793 - accuracy: 0.9128 - val_loss: 0.1847 - val_accuracy: 0.9107\n",
      "Epoch 501/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1798 - accuracy: 0.9125 - val_loss: 0.1848 - val_accuracy: 0.9104\n",
      "Epoch 502/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1796 - accuracy: 0.9133 - val_loss: 0.1848 - val_accuracy: 0.9102\n",
      "Epoch 503/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1799 - accuracy: 0.9127 - val_loss: 0.1849 - val_accuracy: 0.9103\n",
      "Epoch 504/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1789 - accuracy: 0.9141 - val_loss: 0.1848 - val_accuracy: 0.9107\n",
      "Epoch 505/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1795 - accuracy: 0.9134 - val_loss: 0.1847 - val_accuracy: 0.9107\n",
      "Epoch 506/800\n",
      "28831/28831 [==============================] - 0s 16us/step - loss: 0.1792 - accuracy: 0.9135 - val_loss: 0.1848 - val_accuracy: 0.9107\n",
      "Epoch 507/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1793 - accuracy: 0.9131 - val_loss: 0.1849 - val_accuracy: 0.9108\n",
      "Epoch 508/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1799 - accuracy: 0.9136 - val_loss: 0.1847 - val_accuracy: 0.9107\n",
      "Epoch 509/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1793 - accuracy: 0.9134 - val_loss: 0.1847 - val_accuracy: 0.9103\n",
      "Epoch 510/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1793 - accuracy: 0.9128 - val_loss: 0.1846 - val_accuracy: 0.9106\n",
      "Epoch 511/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1790 - accuracy: 0.9143 - val_loss: 0.1846 - val_accuracy: 0.9105\n",
      "Epoch 512/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1813 - accuracy: 0.9121 - val_loss: 0.1847 - val_accuracy: 0.9103\n",
      "Epoch 513/800\n",
      "28831/28831 [==============================] - 0s 16us/step - loss: 0.1797 - accuracy: 0.9131 - val_loss: 0.1848 - val_accuracy: 0.9105\n",
      "Epoch 514/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1795 - accuracy: 0.9128 - val_loss: 0.1847 - val_accuracy: 0.9107\n",
      "Epoch 515/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1801 - accuracy: 0.9135 - val_loss: 0.1846 - val_accuracy: 0.9107\n",
      "Epoch 516/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1803 - accuracy: 0.9122 - val_loss: 0.1845 - val_accuracy: 0.9106\n",
      "Epoch 517/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1797 - accuracy: 0.9128 - val_loss: 0.1846 - val_accuracy: 0.9109\n",
      "Epoch 518/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1795 - accuracy: 0.9132 - val_loss: 0.1847 - val_accuracy: 0.9115\n",
      "Epoch 519/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1806 - accuracy: 0.9141 - val_loss: 0.1847 - val_accuracy: 0.9111\n",
      "Epoch 520/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1803 - accuracy: 0.9121 - val_loss: 0.1846 - val_accuracy: 0.9111\n",
      "Epoch 521/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1803 - accuracy: 0.9130 - val_loss: 0.1846 - val_accuracy: 0.9115\n",
      "Epoch 522/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1794 - accuracy: 0.9109 - val_loss: 0.1847 - val_accuracy: 0.9110\n",
      "Epoch 523/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1806 - accuracy: 0.9117 - val_loss: 0.1846 - val_accuracy: 0.9112\n",
      "Epoch 524/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1795 - accuracy: 0.9126 - val_loss: 0.1846 - val_accuracy: 0.9109\n",
      "Epoch 525/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1800 - accuracy: 0.9108 - val_loss: 0.1847 - val_accuracy: 0.9113\n",
      "Epoch 526/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1792 - accuracy: 0.9133 - val_loss: 0.1847 - val_accuracy: 0.9112\n",
      "Epoch 527/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1787 - accuracy: 0.9142 - val_loss: 0.1847 - val_accuracy: 0.9109\n",
      "Epoch 528/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1786 - accuracy: 0.9126 - val_loss: 0.1846 - val_accuracy: 0.9105\n",
      "Epoch 529/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1815 - accuracy: 0.9135 - val_loss: 0.1846 - val_accuracy: 0.9103\n",
      "Epoch 530/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1807 - accuracy: 0.9116 - val_loss: 0.1846 - val_accuracy: 0.9106\n",
      "Epoch 531/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1795 - accuracy: 0.9150 - val_loss: 0.1846 - val_accuracy: 0.9103\n",
      "Epoch 532/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1792 - accuracy: 0.9139 - val_loss: 0.1845 - val_accuracy: 0.9108\n",
      "Epoch 533/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1800 - accuracy: 0.9136 - val_loss: 0.1845 - val_accuracy: 0.9105\n",
      "Epoch 534/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1798 - accuracy: 0.9120 - val_loss: 0.1847 - val_accuracy: 0.9109\n",
      "Epoch 535/800\n",
      "28831/28831 [==============================] - 1s 19us/step - loss: 0.1777 - accuracy: 0.9139 - val_loss: 0.1846 - val_accuracy: 0.9104\n",
      "Epoch 536/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1787 - accuracy: 0.9128 - val_loss: 0.1846 - val_accuracy: 0.9106\n",
      "Epoch 537/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1807 - accuracy: 0.9117 - val_loss: 0.1846 - val_accuracy: 0.9111\n",
      "Epoch 538/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1787 - accuracy: 0.9127 - val_loss: 0.1846 - val_accuracy: 0.9107\n",
      "Epoch 539/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1812 - accuracy: 0.9124 - val_loss: 0.1846 - val_accuracy: 0.9099\n",
      "Epoch 540/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1798 - accuracy: 0.9130 - val_loss: 0.1846 - val_accuracy: 0.9109\n",
      "Epoch 541/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1796 - accuracy: 0.9138 - val_loss: 0.1846 - val_accuracy: 0.9109\n",
      "Epoch 542/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1803 - accuracy: 0.9124 - val_loss: 0.1846 - val_accuracy: 0.9108\n",
      "Epoch 543/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1798 - accuracy: 0.9123 - val_loss: 0.1846 - val_accuracy: 0.9111\n",
      "Epoch 544/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1779 - accuracy: 0.9135 - val_loss: 0.1844 - val_accuracy: 0.9117\n",
      "Epoch 545/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1796 - accuracy: 0.9125 - val_loss: 0.1844 - val_accuracy: 0.9118\n",
      "Epoch 546/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1802 - accuracy: 0.9129 - val_loss: 0.1844 - val_accuracy: 0.9113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 547/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1790 - accuracy: 0.9143 - val_loss: 0.1844 - val_accuracy: 0.9110\n",
      "Epoch 548/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1799 - accuracy: 0.9140 - val_loss: 0.1846 - val_accuracy: 0.9110\n",
      "Epoch 549/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1795 - accuracy: 0.9140 - val_loss: 0.1845 - val_accuracy: 0.9113\n",
      "Epoch 550/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1784 - accuracy: 0.9143 - val_loss: 0.1846 - val_accuracy: 0.9110\n",
      "Epoch 551/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1807 - accuracy: 0.9132 - val_loss: 0.1845 - val_accuracy: 0.9110\n",
      "Epoch 552/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1786 - accuracy: 0.9141 - val_loss: 0.1846 - val_accuracy: 0.9111\n",
      "Epoch 553/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1789 - accuracy: 0.9136 - val_loss: 0.1846 - val_accuracy: 0.9110\n",
      "Epoch 554/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1790 - accuracy: 0.9109 - val_loss: 0.1846 - val_accuracy: 0.9109\n",
      "Epoch 555/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1782 - accuracy: 0.9149 - val_loss: 0.1847 - val_accuracy: 0.9111\n",
      "Epoch 556/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1803 - accuracy: 0.9144 - val_loss: 0.1847 - val_accuracy: 0.9110\n",
      "Epoch 557/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1794 - accuracy: 0.9138 - val_loss: 0.1846 - val_accuracy: 0.9109\n",
      "Epoch 558/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1793 - accuracy: 0.9128 - val_loss: 0.1845 - val_accuracy: 0.9111\n",
      "Epoch 559/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1788 - accuracy: 0.9139 - val_loss: 0.1845 - val_accuracy: 0.9111\n",
      "Epoch 560/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1797 - accuracy: 0.9129 - val_loss: 0.1846 - val_accuracy: 0.9107\n",
      "Epoch 561/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1779 - accuracy: 0.9130 - val_loss: 0.1845 - val_accuracy: 0.9103\n",
      "Epoch 562/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1792 - accuracy: 0.9134 - val_loss: 0.1845 - val_accuracy: 0.9106\n",
      "Epoch 563/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1800 - accuracy: 0.9128 - val_loss: 0.1845 - val_accuracy: 0.9107\n",
      "Epoch 564/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1803 - accuracy: 0.9138 - val_loss: 0.1846 - val_accuracy: 0.9106\n",
      "Epoch 565/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1792 - accuracy: 0.9141 - val_loss: 0.1846 - val_accuracy: 0.9107\n",
      "Epoch 566/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1776 - accuracy: 0.9137 - val_loss: 0.1846 - val_accuracy: 0.9107\n",
      "Epoch 567/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1790 - accuracy: 0.9128 - val_loss: 0.1847 - val_accuracy: 0.9107\n",
      "Epoch 568/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1792 - accuracy: 0.9143 - val_loss: 0.1847 - val_accuracy: 0.9115\n",
      "Epoch 569/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1795 - accuracy: 0.9130 - val_loss: 0.1846 - val_accuracy: 0.9109\n",
      "Epoch 570/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1787 - accuracy: 0.9130 - val_loss: 0.1845 - val_accuracy: 0.9108\n",
      "Epoch 571/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1779 - accuracy: 0.9137 - val_loss: 0.1846 - val_accuracy: 0.9109\n",
      "Epoch 572/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1779 - accuracy: 0.9143 - val_loss: 0.1846 - val_accuracy: 0.9107\n",
      "Epoch 573/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1803 - accuracy: 0.9130 - val_loss: 0.1846 - val_accuracy: 0.9111\n",
      "Epoch 574/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1788 - accuracy: 0.9133 - val_loss: 0.1845 - val_accuracy: 0.9110\n",
      "Epoch 575/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1797 - accuracy: 0.9133 - val_loss: 0.1846 - val_accuracy: 0.9111\n",
      "Epoch 576/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1791 - accuracy: 0.9140 - val_loss: 0.1846 - val_accuracy: 0.9110\n",
      "Epoch 577/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1797 - accuracy: 0.9132 - val_loss: 0.1845 - val_accuracy: 0.9107\n",
      "Epoch 578/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1794 - accuracy: 0.9152 - val_loss: 0.1845 - val_accuracy: 0.9109\n",
      "Epoch 579/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1789 - accuracy: 0.9132 - val_loss: 0.1847 - val_accuracy: 0.9114\n",
      "Epoch 580/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1781 - accuracy: 0.9120 - val_loss: 0.1847 - val_accuracy: 0.9115\n",
      "Epoch 581/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1788 - accuracy: 0.9130 - val_loss: 0.1847 - val_accuracy: 0.9111\n",
      "Epoch 582/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1795 - accuracy: 0.9117 - val_loss: 0.1846 - val_accuracy: 0.9111\n",
      "Epoch 583/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1783 - accuracy: 0.9138 - val_loss: 0.1848 - val_accuracy: 0.9118\n",
      "Epoch 584/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1814 - accuracy: 0.9130 - val_loss: 0.1846 - val_accuracy: 0.9114\n",
      "Epoch 585/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1787 - accuracy: 0.9146 - val_loss: 0.1847 - val_accuracy: 0.9116\n",
      "Epoch 586/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1790 - accuracy: 0.9120 - val_loss: 0.1847 - val_accuracy: 0.9120\n",
      "Epoch 587/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1773 - accuracy: 0.9147 - val_loss: 0.1848 - val_accuracy: 0.9120\n",
      "Epoch 588/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1785 - accuracy: 0.9138 - val_loss: 0.1848 - val_accuracy: 0.9118\n",
      "Epoch 589/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1796 - accuracy: 0.9125 - val_loss: 0.1848 - val_accuracy: 0.9117\n",
      "Epoch 590/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1798 - accuracy: 0.9129 - val_loss: 0.1847 - val_accuracy: 0.9112\n",
      "Epoch 591/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1787 - accuracy: 0.9133 - val_loss: 0.1847 - val_accuracy: 0.9113\n",
      "Epoch 592/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1794 - accuracy: 0.9129 - val_loss: 0.1847 - val_accuracy: 0.9114\n",
      "Epoch 593/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1792 - accuracy: 0.9133 - val_loss: 0.1847 - val_accuracy: 0.9115\n",
      "Epoch 594/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1778 - accuracy: 0.9137 - val_loss: 0.1848 - val_accuracy: 0.9115\n",
      "Epoch 595/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1778 - accuracy: 0.9131 - val_loss: 0.1848 - val_accuracy: 0.9115\n",
      "Epoch 596/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1772 - accuracy: 0.9133 - val_loss: 0.1847 - val_accuracy: 0.9114\n",
      "Epoch 597/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1803 - accuracy: 0.9113 - val_loss: 0.1846 - val_accuracy: 0.9118\n",
      "Epoch 598/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1787 - accuracy: 0.9137 - val_loss: 0.1847 - val_accuracy: 0.9114\n",
      "Epoch 599/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1794 - accuracy: 0.9130 - val_loss: 0.1847 - val_accuracy: 0.9118\n",
      "Epoch 600/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1785 - accuracy: 0.9135 - val_loss: 0.1847 - val_accuracy: 0.9119\n",
      "Epoch 601/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1803 - accuracy: 0.9129 - val_loss: 0.1846 - val_accuracy: 0.9119\n",
      "Epoch 602/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1778 - accuracy: 0.9122 - val_loss: 0.1848 - val_accuracy: 0.9107\n",
      "Epoch 603/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1788 - accuracy: 0.9128 - val_loss: 0.1847 - val_accuracy: 0.9110\n",
      "Epoch 604/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1790 - accuracy: 0.9121 - val_loss: 0.1848 - val_accuracy: 0.9108\n",
      "Epoch 605/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1793 - accuracy: 0.9147 - val_loss: 0.1848 - val_accuracy: 0.9113\n",
      "Epoch 606/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1794 - accuracy: 0.9129 - val_loss: 0.1847 - val_accuracy: 0.9106\n",
      "Epoch 607/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1776 - accuracy: 0.9141 - val_loss: 0.1847 - val_accuracy: 0.9109\n",
      "Epoch 608/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1775 - accuracy: 0.9139 - val_loss: 0.1846 - val_accuracy: 0.9109\n",
      "Epoch 609/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1800 - accuracy: 0.9134 - val_loss: 0.1848 - val_accuracy: 0.9114\n",
      "Epoch 610/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1792 - accuracy: 0.9135 - val_loss: 0.1850 - val_accuracy: 0.9109\n",
      "Epoch 611/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1792 - accuracy: 0.9136 - val_loss: 0.1849 - val_accuracy: 0.9109\n",
      "Epoch 612/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1791 - accuracy: 0.9122 - val_loss: 0.1848 - val_accuracy: 0.9111\n",
      "Epoch 613/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1785 - accuracy: 0.9140 - val_loss: 0.1847 - val_accuracy: 0.9108\n",
      "Epoch 614/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1790 - accuracy: 0.9151 - val_loss: 0.1847 - val_accuracy: 0.9108\n",
      "Epoch 615/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1784 - accuracy: 0.9127 - val_loss: 0.1847 - val_accuracy: 0.9113\n",
      "Epoch 616/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1785 - accuracy: 0.9133 - val_loss: 0.1850 - val_accuracy: 0.9111\n",
      "Epoch 617/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1782 - accuracy: 0.9144 - val_loss: 0.1847 - val_accuracy: 0.9112\n",
      "Epoch 618/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1800 - accuracy: 0.9135 - val_loss: 0.1848 - val_accuracy: 0.9112\n",
      "Epoch 619/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1787 - accuracy: 0.9134 - val_loss: 0.1847 - val_accuracy: 0.9115\n",
      "Epoch 620/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1787 - accuracy: 0.9150 - val_loss: 0.1847 - val_accuracy: 0.9111\n",
      "Epoch 621/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1789 - accuracy: 0.9139 - val_loss: 0.1847 - val_accuracy: 0.9114\n",
      "Epoch 622/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1790 - accuracy: 0.9131 - val_loss: 0.1846 - val_accuracy: 0.9109\n",
      "Epoch 623/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1784 - accuracy: 0.9143 - val_loss: 0.1846 - val_accuracy: 0.9112\n",
      "Epoch 624/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1792 - accuracy: 0.9132 - val_loss: 0.1846 - val_accuracy: 0.9112\n",
      "Epoch 625/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1795 - accuracy: 0.9121 - val_loss: 0.1846 - val_accuracy: 0.9113\n",
      "Epoch 626/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1793 - accuracy: 0.9126 - val_loss: 0.1845 - val_accuracy: 0.9111\n",
      "Epoch 627/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1789 - accuracy: 0.9153 - val_loss: 0.1845 - val_accuracy: 0.9116\n",
      "Epoch 628/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1785 - accuracy: 0.9126 - val_loss: 0.1845 - val_accuracy: 0.9115\n",
      "Epoch 629/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1779 - accuracy: 0.9132 - val_loss: 0.1845 - val_accuracy: 0.9111\n",
      "Epoch 630/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1778 - accuracy: 0.9146 - val_loss: 0.1847 - val_accuracy: 0.9111\n",
      "Epoch 631/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1772 - accuracy: 0.9139 - val_loss: 0.1847 - val_accuracy: 0.9112\n",
      "Epoch 632/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1774 - accuracy: 0.9136 - val_loss: 0.1846 - val_accuracy: 0.9103\n",
      "Epoch 633/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1796 - accuracy: 0.9119 - val_loss: 0.1846 - val_accuracy: 0.9105\n",
      "Epoch 634/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1776 - accuracy: 0.9131 - val_loss: 0.1847 - val_accuracy: 0.9110\n",
      "Epoch 635/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1805 - accuracy: 0.9122 - val_loss: 0.1847 - val_accuracy: 0.9111\n",
      "Epoch 636/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1793 - accuracy: 0.9135 - val_loss: 0.1845 - val_accuracy: 0.9106\n",
      "Epoch 637/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1779 - accuracy: 0.9140 - val_loss: 0.1846 - val_accuracy: 0.9108\n",
      "Epoch 638/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1790 - accuracy: 0.9137 - val_loss: 0.1847 - val_accuracy: 0.9107\n",
      "Epoch 639/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1781 - accuracy: 0.9128 - val_loss: 0.1847 - val_accuracy: 0.9114\n",
      "Epoch 640/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1793 - accuracy: 0.9121 - val_loss: 0.1845 - val_accuracy: 0.9109\n",
      "Epoch 641/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1774 - accuracy: 0.9137 - val_loss: 0.1847 - val_accuracy: 0.9111\n",
      "Epoch 642/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1792 - accuracy: 0.9131 - val_loss: 0.1846 - val_accuracy: 0.9102\n",
      "Epoch 643/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1784 - accuracy: 0.9130 - val_loss: 0.1848 - val_accuracy: 0.9101\n",
      "Epoch 644/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1790 - accuracy: 0.9134 - val_loss: 0.1847 - val_accuracy: 0.9111\n",
      "Epoch 645/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1783 - accuracy: 0.9144 - val_loss: 0.1846 - val_accuracy: 0.9107\n",
      "Epoch 646/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1782 - accuracy: 0.9133 - val_loss: 0.1847 - val_accuracy: 0.9110\n",
      "Epoch 647/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1781 - accuracy: 0.9137 - val_loss: 0.1848 - val_accuracy: 0.9107\n",
      "Epoch 648/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1781 - accuracy: 0.9135 - val_loss: 0.1847 - val_accuracy: 0.9107\n",
      "Epoch 649/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1791 - accuracy: 0.9142 - val_loss: 0.1848 - val_accuracy: 0.9103\n",
      "Epoch 650/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1762 - accuracy: 0.9152 - val_loss: 0.1847 - val_accuracy: 0.9111\n",
      "Epoch 651/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1773 - accuracy: 0.9135 - val_loss: 0.1846 - val_accuracy: 0.9112\n",
      "Epoch 652/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1776 - accuracy: 0.9140 - val_loss: 0.1846 - val_accuracy: 0.9108\n",
      "Epoch 653/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1787 - accuracy: 0.9135 - val_loss: 0.1847 - val_accuracy: 0.9110\n",
      "Epoch 654/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1791 - accuracy: 0.9126 - val_loss: 0.1848 - val_accuracy: 0.9112\n",
      "Epoch 655/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1776 - accuracy: 0.9148 - val_loss: 0.1850 - val_accuracy: 0.9110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 656/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1765 - accuracy: 0.9132 - val_loss: 0.1849 - val_accuracy: 0.9111\n",
      "Epoch 657/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1779 - accuracy: 0.9132 - val_loss: 0.1849 - val_accuracy: 0.9107\n",
      "Epoch 658/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1802 - accuracy: 0.9135 - val_loss: 0.1849 - val_accuracy: 0.9105\n",
      "Epoch 659/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1777 - accuracy: 0.9121 - val_loss: 0.1849 - val_accuracy: 0.9104\n",
      "Epoch 660/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1794 - accuracy: 0.9142 - val_loss: 0.1850 - val_accuracy: 0.9106\n",
      "Epoch 661/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1778 - accuracy: 0.9156 - val_loss: 0.1849 - val_accuracy: 0.9107\n",
      "Epoch 662/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1788 - accuracy: 0.9136 - val_loss: 0.1850 - val_accuracy: 0.9101\n",
      "Epoch 663/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1784 - accuracy: 0.9147 - val_loss: 0.1849 - val_accuracy: 0.9107\n",
      "Epoch 664/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1783 - accuracy: 0.9116 - val_loss: 0.1848 - val_accuracy: 0.9105\n",
      "Epoch 665/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1787 - accuracy: 0.9143 - val_loss: 0.1849 - val_accuracy: 0.9103\n",
      "Epoch 666/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1768 - accuracy: 0.9146 - val_loss: 0.1851 - val_accuracy: 0.9104\n",
      "Epoch 667/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1774 - accuracy: 0.9141 - val_loss: 0.1850 - val_accuracy: 0.9104\n",
      "Epoch 668/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1792 - accuracy: 0.9130 - val_loss: 0.1849 - val_accuracy: 0.9104\n",
      "Epoch 669/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1791 - accuracy: 0.9138 - val_loss: 0.1850 - val_accuracy: 0.9107\n",
      "Epoch 670/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1773 - accuracy: 0.9143 - val_loss: 0.1850 - val_accuracy: 0.9114\n",
      "Epoch 671/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1774 - accuracy: 0.9131 - val_loss: 0.1849 - val_accuracy: 0.9111\n",
      "Epoch 672/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1789 - accuracy: 0.9129 - val_loss: 0.1851 - val_accuracy: 0.9103\n",
      "Epoch 673/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1780 - accuracy: 0.9138 - val_loss: 0.1850 - val_accuracy: 0.9105\n",
      "Epoch 674/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1774 - accuracy: 0.9153 - val_loss: 0.1850 - val_accuracy: 0.9102\n",
      "Epoch 675/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1788 - accuracy: 0.9136 - val_loss: 0.1848 - val_accuracy: 0.9101\n",
      "Epoch 676/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1776 - accuracy: 0.9131 - val_loss: 0.1849 - val_accuracy: 0.9104\n",
      "Epoch 677/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1779 - accuracy: 0.9129 - val_loss: 0.1850 - val_accuracy: 0.9107\n",
      "Epoch 678/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1780 - accuracy: 0.9139 - val_loss: 0.1848 - val_accuracy: 0.9104\n",
      "Epoch 679/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1775 - accuracy: 0.9143 - val_loss: 0.1849 - val_accuracy: 0.9104\n",
      "Epoch 680/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1768 - accuracy: 0.9141 - val_loss: 0.1849 - val_accuracy: 0.9104\n",
      "Epoch 681/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1772 - accuracy: 0.9126 - val_loss: 0.1850 - val_accuracy: 0.9103\n",
      "Epoch 682/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1786 - accuracy: 0.9126 - val_loss: 0.1849 - val_accuracy: 0.9107\n",
      "Epoch 683/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1787 - accuracy: 0.9139 - val_loss: 0.1849 - val_accuracy: 0.9107\n",
      "Epoch 684/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1785 - accuracy: 0.9134 - val_loss: 0.1848 - val_accuracy: 0.9111\n",
      "Epoch 685/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1772 - accuracy: 0.9134 - val_loss: 0.1849 - val_accuracy: 0.9109\n",
      "Epoch 686/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1769 - accuracy: 0.9142 - val_loss: 0.1850 - val_accuracy: 0.9109\n",
      "Epoch 687/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1774 - accuracy: 0.9143 - val_loss: 0.1849 - val_accuracy: 0.9110\n",
      "Epoch 688/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1769 - accuracy: 0.9138 - val_loss: 0.1848 - val_accuracy: 0.9107\n",
      "Epoch 689/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1793 - accuracy: 0.9129 - val_loss: 0.1849 - val_accuracy: 0.9108\n",
      "Epoch 690/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1775 - accuracy: 0.9135 - val_loss: 0.1848 - val_accuracy: 0.9107\n",
      "Epoch 691/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1774 - accuracy: 0.9145 - val_loss: 0.1849 - val_accuracy: 0.9104\n",
      "Epoch 692/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1781 - accuracy: 0.9142 - val_loss: 0.1849 - val_accuracy: 0.9104\n",
      "Epoch 693/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1792 - accuracy: 0.9133 - val_loss: 0.1849 - val_accuracy: 0.9107\n",
      "Epoch 694/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1778 - accuracy: 0.9121 - val_loss: 0.1849 - val_accuracy: 0.9103\n",
      "Epoch 695/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1785 - accuracy: 0.9147 - val_loss: 0.1850 - val_accuracy: 0.9104\n",
      "Epoch 696/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1775 - accuracy: 0.9128 - val_loss: 0.1851 - val_accuracy: 0.9109\n",
      "Epoch 697/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1775 - accuracy: 0.9140 - val_loss: 0.1849 - val_accuracy: 0.9109\n",
      "Epoch 698/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1794 - accuracy: 0.9126 - val_loss: 0.1849 - val_accuracy: 0.9108\n",
      "Epoch 699/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1779 - accuracy: 0.9137 - val_loss: 0.1851 - val_accuracy: 0.9107\n",
      "Epoch 700/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1774 - accuracy: 0.9148 - val_loss: 0.1850 - val_accuracy: 0.9105\n",
      "Epoch 701/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1780 - accuracy: 0.9143 - val_loss: 0.1851 - val_accuracy: 0.9104\n",
      "Epoch 702/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1794 - accuracy: 0.9125 - val_loss: 0.1852 - val_accuracy: 0.9096\n",
      "Epoch 703/800\n",
      "28831/28831 [==============================] - 0s 16us/step - loss: 0.1769 - accuracy: 0.9148 - val_loss: 0.1851 - val_accuracy: 0.9107\n",
      "Epoch 704/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1780 - accuracy: 0.9137 - val_loss: 0.1850 - val_accuracy: 0.9104\n",
      "Epoch 705/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1787 - accuracy: 0.9145 - val_loss: 0.1850 - val_accuracy: 0.9106\n",
      "Epoch 706/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1775 - accuracy: 0.9136 - val_loss: 0.1852 - val_accuracy: 0.9106\n",
      "Epoch 707/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1778 - accuracy: 0.9140 - val_loss: 0.1850 - val_accuracy: 0.9102\n",
      "Epoch 708/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1776 - accuracy: 0.9124 - val_loss: 0.1850 - val_accuracy: 0.9107\n",
      "Epoch 709/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1774 - accuracy: 0.9127 - val_loss: 0.1850 - val_accuracy: 0.9102\n",
      "Epoch 710/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1780 - accuracy: 0.9127 - val_loss: 0.1849 - val_accuracy: 0.9100\n",
      "Epoch 711/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1775 - accuracy: 0.9153 - val_loss: 0.1850 - val_accuracy: 0.9107\n",
      "Epoch 712/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1776 - accuracy: 0.9147 - val_loss: 0.1849 - val_accuracy: 0.9103\n",
      "Epoch 713/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1783 - accuracy: 0.9134 - val_loss: 0.1851 - val_accuracy: 0.9103\n",
      "Epoch 714/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1779 - accuracy: 0.9127 - val_loss: 0.1851 - val_accuracy: 0.9107\n",
      "Epoch 715/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1767 - accuracy: 0.9150 - val_loss: 0.1850 - val_accuracy: 0.9110\n",
      "Epoch 716/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1770 - accuracy: 0.9147 - val_loss: 0.1850 - val_accuracy: 0.9106\n",
      "Epoch 717/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1765 - accuracy: 0.9145 - val_loss: 0.1850 - val_accuracy: 0.9104\n",
      "Epoch 718/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1785 - accuracy: 0.9133 - val_loss: 0.1849 - val_accuracy: 0.9104\n",
      "Epoch 719/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1774 - accuracy: 0.9139 - val_loss: 0.1849 - val_accuracy: 0.9107\n",
      "Epoch 720/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1769 - accuracy: 0.9147 - val_loss: 0.1850 - val_accuracy: 0.9108\n",
      "Epoch 721/800\n",
      "28831/28831 [==============================] - 0s 16us/step - loss: 0.1778 - accuracy: 0.9134 - val_loss: 0.1851 - val_accuracy: 0.9104\n",
      "Epoch 722/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1790 - accuracy: 0.9149 - val_loss: 0.1851 - val_accuracy: 0.9108\n",
      "Epoch 723/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1789 - accuracy: 0.9134 - val_loss: 0.1849 - val_accuracy: 0.9103\n",
      "Epoch 724/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1785 - accuracy: 0.9134 - val_loss: 0.1851 - val_accuracy: 0.9110\n",
      "Epoch 725/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1780 - accuracy: 0.9126 - val_loss: 0.1850 - val_accuracy: 0.9105\n",
      "Epoch 726/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1773 - accuracy: 0.9138 - val_loss: 0.1851 - val_accuracy: 0.9106\n",
      "Epoch 727/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1787 - accuracy: 0.9126 - val_loss: 0.1851 - val_accuracy: 0.9103\n",
      "Epoch 728/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1776 - accuracy: 0.9135 - val_loss: 0.1851 - val_accuracy: 0.9102\n",
      "Epoch 729/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1782 - accuracy: 0.9130 - val_loss: 0.1849 - val_accuracy: 0.9106\n",
      "Epoch 730/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1775 - accuracy: 0.9137 - val_loss: 0.1848 - val_accuracy: 0.9103\n",
      "Epoch 731/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1785 - accuracy: 0.9133 - val_loss: 0.1848 - val_accuracy: 0.9103\n",
      "Epoch 732/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1758 - accuracy: 0.9158 - val_loss: 0.1848 - val_accuracy: 0.9103\n",
      "Epoch 733/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1791 - accuracy: 0.9124 - val_loss: 0.1848 - val_accuracy: 0.9102\n",
      "Epoch 734/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1766 - accuracy: 0.9127 - val_loss: 0.1847 - val_accuracy: 0.9099\n",
      "Epoch 735/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1764 - accuracy: 0.9150 - val_loss: 0.1848 - val_accuracy: 0.9098\n",
      "Epoch 736/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1765 - accuracy: 0.9136 - val_loss: 0.1849 - val_accuracy: 0.9101\n",
      "Epoch 737/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1786 - accuracy: 0.9129 - val_loss: 0.1848 - val_accuracy: 0.9101\n",
      "Epoch 738/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1768 - accuracy: 0.9144 - val_loss: 0.1848 - val_accuracy: 0.9103\n",
      "Epoch 739/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1775 - accuracy: 0.9129 - val_loss: 0.1848 - val_accuracy: 0.9102\n",
      "Epoch 740/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1765 - accuracy: 0.9139 - val_loss: 0.1848 - val_accuracy: 0.9102\n",
      "Epoch 741/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1780 - accuracy: 0.9138 - val_loss: 0.1848 - val_accuracy: 0.9105\n",
      "Epoch 742/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1779 - accuracy: 0.9136 - val_loss: 0.1848 - val_accuracy: 0.9104\n",
      "Epoch 743/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1772 - accuracy: 0.9144 - val_loss: 0.1848 - val_accuracy: 0.9103\n",
      "Epoch 744/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1781 - accuracy: 0.9147 - val_loss: 0.1849 - val_accuracy: 0.9099\n",
      "Epoch 745/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1776 - accuracy: 0.9117 - val_loss: 0.1849 - val_accuracy: 0.9100\n",
      "Epoch 746/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1794 - accuracy: 0.9114 - val_loss: 0.1849 - val_accuracy: 0.9100\n",
      "Epoch 747/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1781 - accuracy: 0.9137 - val_loss: 0.1850 - val_accuracy: 0.9098\n",
      "Epoch 748/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1764 - accuracy: 0.9124 - val_loss: 0.1850 - val_accuracy: 0.9102\n",
      "Epoch 749/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1772 - accuracy: 0.9136 - val_loss: 0.1849 - val_accuracy: 0.9099\n",
      "Epoch 750/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1763 - accuracy: 0.9159 - val_loss: 0.1851 - val_accuracy: 0.9104\n",
      "Epoch 751/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1768 - accuracy: 0.9138 - val_loss: 0.1850 - val_accuracy: 0.9103\n",
      "Epoch 752/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1769 - accuracy: 0.9131 - val_loss: 0.1850 - val_accuracy: 0.9104\n",
      "Epoch 753/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1778 - accuracy: 0.9134 - val_loss: 0.1850 - val_accuracy: 0.9101\n",
      "Epoch 754/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1777 - accuracy: 0.9131 - val_loss: 0.1850 - val_accuracy: 0.9098\n",
      "Epoch 755/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1774 - accuracy: 0.9141 - val_loss: 0.1849 - val_accuracy: 0.9103\n",
      "Epoch 756/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1779 - accuracy: 0.9147 - val_loss: 0.1850 - val_accuracy: 0.9100\n",
      "Epoch 757/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1777 - accuracy: 0.9137 - val_loss: 0.1850 - val_accuracy: 0.9102\n",
      "Epoch 758/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1771 - accuracy: 0.9138 - val_loss: 0.1850 - val_accuracy: 0.9099\n",
      "Epoch 759/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1786 - accuracy: 0.9133 - val_loss: 0.1850 - val_accuracy: 0.9101\n",
      "Epoch 760/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1779 - accuracy: 0.9140 - val_loss: 0.1851 - val_accuracy: 0.9101\n",
      "Epoch 761/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1777 - accuracy: 0.9138 - val_loss: 0.1850 - val_accuracy: 0.9103\n",
      "Epoch 762/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1775 - accuracy: 0.9138 - val_loss: 0.1850 - val_accuracy: 0.9098\n",
      "Epoch 763/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1769 - accuracy: 0.9123 - val_loss: 0.1850 - val_accuracy: 0.9100\n",
      "Epoch 764/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1777 - accuracy: 0.9138 - val_loss: 0.1850 - val_accuracy: 0.9098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 765/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1767 - accuracy: 0.9138 - val_loss: 0.1851 - val_accuracy: 0.9098\n",
      "Epoch 766/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1774 - accuracy: 0.9136 - val_loss: 0.1850 - val_accuracy: 0.9101\n",
      "Epoch 767/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1777 - accuracy: 0.9142 - val_loss: 0.1850 - val_accuracy: 0.9106\n",
      "Epoch 768/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1781 - accuracy: 0.9140 - val_loss: 0.1851 - val_accuracy: 0.9103\n",
      "Epoch 769/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1774 - accuracy: 0.9149 - val_loss: 0.1849 - val_accuracy: 0.9103\n",
      "Epoch 770/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1761 - accuracy: 0.9131 - val_loss: 0.1850 - val_accuracy: 0.9106\n",
      "Epoch 771/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1767 - accuracy: 0.9126 - val_loss: 0.1849 - val_accuracy: 0.9102\n",
      "Epoch 772/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1769 - accuracy: 0.9136 - val_loss: 0.1849 - val_accuracy: 0.9106\n",
      "Epoch 773/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1756 - accuracy: 0.9145 - val_loss: 0.1850 - val_accuracy: 0.9102\n",
      "Epoch 774/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1763 - accuracy: 0.9138 - val_loss: 0.1849 - val_accuracy: 0.9103\n",
      "Epoch 775/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1781 - accuracy: 0.9140 - val_loss: 0.1850 - val_accuracy: 0.9105\n",
      "Epoch 776/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1775 - accuracy: 0.9133 - val_loss: 0.1852 - val_accuracy: 0.9104\n",
      "Epoch 777/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1770 - accuracy: 0.9134 - val_loss: 0.1851 - val_accuracy: 0.9105\n",
      "Epoch 778/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1764 - accuracy: 0.9139 - val_loss: 0.1850 - val_accuracy: 0.9103\n",
      "Epoch 779/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1771 - accuracy: 0.9151 - val_loss: 0.1851 - val_accuracy: 0.9103\n",
      "Epoch 780/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1767 - accuracy: 0.9143 - val_loss: 0.1851 - val_accuracy: 0.9102\n",
      "Epoch 781/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1770 - accuracy: 0.9120 - val_loss: 0.1854 - val_accuracy: 0.9103\n",
      "Epoch 782/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1777 - accuracy: 0.9151 - val_loss: 0.1853 - val_accuracy: 0.9104\n",
      "Epoch 783/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1785 - accuracy: 0.9128 - val_loss: 0.1852 - val_accuracy: 0.9102\n",
      "Epoch 784/800\n",
      "28831/28831 [==============================] - 0s 16us/step - loss: 0.1781 - accuracy: 0.9139 - val_loss: 0.1851 - val_accuracy: 0.9103\n",
      "Epoch 785/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1746 - accuracy: 0.9146 - val_loss: 0.1852 - val_accuracy: 0.9103\n",
      "Epoch 786/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1763 - accuracy: 0.9128 - val_loss: 0.1852 - val_accuracy: 0.9099\n",
      "Epoch 787/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1785 - accuracy: 0.9134 - val_loss: 0.1851 - val_accuracy: 0.9094\n",
      "Epoch 788/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1764 - accuracy: 0.9148 - val_loss: 0.1852 - val_accuracy: 0.9104\n",
      "Epoch 789/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1768 - accuracy: 0.9159 - val_loss: 0.1850 - val_accuracy: 0.9095\n",
      "Epoch 790/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1775 - accuracy: 0.9135 - val_loss: 0.1851 - val_accuracy: 0.9098\n",
      "Epoch 791/800\n",
      "28831/28831 [==============================] - 1s 17us/step - loss: 0.1780 - accuracy: 0.9131 - val_loss: 0.1851 - val_accuracy: 0.9098\n",
      "Epoch 792/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1760 - accuracy: 0.9161 - val_loss: 0.1851 - val_accuracy: 0.9103\n",
      "Epoch 793/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1762 - accuracy: 0.9155 - val_loss: 0.1851 - val_accuracy: 0.9098\n",
      "Epoch 794/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1780 - accuracy: 0.9124 - val_loss: 0.1852 - val_accuracy: 0.9098\n",
      "Epoch 795/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1784 - accuracy: 0.9138 - val_loss: 0.1849 - val_accuracy: 0.9096\n",
      "Epoch 796/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1774 - accuracy: 0.9151 - val_loss: 0.1850 - val_accuracy: 0.9098\n",
      "Epoch 797/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1763 - accuracy: 0.9147 - val_loss: 0.1850 - val_accuracy: 0.9097\n",
      "Epoch 798/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1768 - accuracy: 0.9125 - val_loss: 0.1850 - val_accuracy: 0.9095\n",
      "Epoch 799/800\n",
      "28831/28831 [==============================] - 0s 17us/step - loss: 0.1764 - accuracy: 0.9143 - val_loss: 0.1851 - val_accuracy: 0.9097\n",
      "Epoch 800/800\n",
      "28831/28831 [==============================] - 1s 18us/step - loss: 0.1763 - accuracy: 0.9152 - val_loss: 0.1849 - val_accuracy: 0.9102\n"
     ]
    }
   ],
   "source": [
    "from keras import optimizers\n",
    "sgd = optimizers.SGD(lr=0.01, clipnorm=1.)\n",
    "#sgd = optimizers.SGD(lr=0.01, clipnorm=1.)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "Modelfit=model.fit(X_train_std, y_train, epochs=800, batch_size=128, verbose=1,validation_data=(X_test_std, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(Modelfit.history['accuracy'][1:])\n",
    "plt.plot(Modelfit.history['val_accuracy'][1:])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(Modelfit.history['loss'][1:])\n",
    "plt.plot(Modelfit.history['val_loss'][1:])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 91.02%\n",
      "Balanced Accuracy: 74.38%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95     10934\n",
      "           1       0.63      0.53      0.58      1423\n",
      "\n",
      "    accuracy                           0.91     12357\n",
      "   macro avg       0.79      0.74      0.76     12357\n",
      "weighted avg       0.90      0.91      0.91     12357\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_classes(X_test_std)\n",
    "\n",
    "print(f\"Accuracy: {round(metrics.accuracy_score(y_test, y_pred)*100, 2)}%\")\n",
    "print(f\"Balanced Accuracy: {round(metrics.balanced_accuracy_score(y_test, y_pred)*100, 2)}%\")\n",
    "\n",
    "print(classification_report(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(X_SMOTE)\n",
    "X_SMOTE_std = scaler.transform(X_SMOTE)\n",
    "X_test_std = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_61 (Dense)             (None, 16)                944       \n",
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dropout_42 (Dropout)         (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 1,089\n",
      "Trainable params: 1,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelSMOTE = Sequential()\n",
    "#model.add(Dense(500, activation='relu', input_dim=58))\n",
    "#model.add(Dropout(0.2))\n",
    "modelSMOTE.add(Dense(16, activation='relu',input_dim=58))\n",
    "modelSMOTE.add(Dropout(0.2))\n",
    "modelSMOTE.add(Dense(8, activation='relu'))\n",
    "modelSMOTE.add(Dropout(0.2))\n",
    "modelSMOTE.add(Dense(1, activation='sigmoid'))\n",
    "#model.output_shape\n",
    "modelSMOTE.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 51228 samples, validate on 12357 samples\n",
      "Epoch 1/200\n",
      "51228/51228 [==============================] - 3s 62us/step - loss: 0.2450 - accuracy: 0.9015 - val_loss: 0.2220 - val_accuracy: 0.9033\n",
      "Epoch 2/200\n",
      "51228/51228 [==============================] - 2s 39us/step - loss: 0.1454 - accuracy: 0.9426 - val_loss: 0.1983 - val_accuracy: 0.9073\n",
      "Epoch 3/200\n",
      "51228/51228 [==============================] - 2s 39us/step - loss: 0.1286 - accuracy: 0.9459 - val_loss: 0.1904 - val_accuracy: 0.9098\n",
      "Epoch 4/200\n",
      "51228/51228 [==============================] - 2s 39us/step - loss: 0.1214 - accuracy: 0.9481 - val_loss: 0.1883 - val_accuracy: 0.9101\n",
      "Epoch 5/200\n",
      "51228/51228 [==============================] - 2s 40us/step - loss: 0.1168 - accuracy: 0.9494 - val_loss: 0.1879 - val_accuracy: 0.9113\n",
      "Epoch 6/200\n",
      "51228/51228 [==============================] - 2s 39us/step - loss: 0.1162 - accuracy: 0.9484 - val_loss: 0.1874 - val_accuracy: 0.9113\n",
      "Epoch 7/200\n",
      "51228/51228 [==============================] - 2s 40us/step - loss: 0.1143 - accuracy: 0.9480 - val_loss: 0.1868 - val_accuracy: 0.9103\n",
      "Epoch 8/200\n",
      "51228/51228 [==============================] - 2s 39us/step - loss: 0.1144 - accuracy: 0.9458 - val_loss: 0.1860 - val_accuracy: 0.9107\n",
      "Epoch 9/200\n",
      "51228/51228 [==============================] - 2s 39us/step - loss: 0.1129 - accuracy: 0.9471 - val_loss: 0.1851 - val_accuracy: 0.9118\n",
      "Epoch 10/200\n",
      "51228/51228 [==============================] - 2s 39us/step - loss: 0.1116 - accuracy: 0.9474 - val_loss: 0.1864 - val_accuracy: 0.9102\n",
      "Epoch 11/200\n",
      "51228/51228 [==============================] - 2s 40us/step - loss: 0.1105 - accuracy: 0.9486 - val_loss: 0.1865 - val_accuracy: 0.9102\n",
      "Epoch 12/200\n",
      "51228/51228 [==============================] - 2s 39us/step - loss: 0.1103 - accuracy: 0.9466 - val_loss: 0.1861 - val_accuracy: 0.9093\n",
      "Epoch 13/200\n",
      "51228/51228 [==============================] - 2s 40us/step - loss: 0.1110 - accuracy: 0.9466 - val_loss: 0.1857 - val_accuracy: 0.9107\n",
      "Epoch 14/200\n",
      "51228/51228 [==============================] - 2s 39us/step - loss: 0.1100 - accuracy: 0.9474 - val_loss: 0.1856 - val_accuracy: 0.9108\n",
      "Epoch 15/200\n",
      "51228/51228 [==============================] - 2s 40us/step - loss: 0.1096 - accuracy: 0.9480 - val_loss: 0.1857 - val_accuracy: 0.9123\n",
      "Epoch 16/200\n",
      "51228/51228 [==============================] - 2s 39us/step - loss: 0.1085 - accuracy: 0.9471 - val_loss: 0.1849 - val_accuracy: 0.9120\n",
      "Epoch 17/200\n",
      "51228/51228 [==============================] - 2s 39us/step - loss: 0.1090 - accuracy: 0.9482 - val_loss: 0.1831 - val_accuracy: 0.9128\n",
      "Epoch 18/200\n",
      "51228/51228 [==============================] - 2s 39us/step - loss: 0.1088 - accuracy: 0.9473 - val_loss: 0.1843 - val_accuracy: 0.9117\n",
      "Epoch 19/200\n",
      "51228/51228 [==============================] - 2s 39us/step - loss: 0.1080 - accuracy: 0.9495 - val_loss: 0.1831 - val_accuracy: 0.9121\n",
      "Epoch 20/200\n",
      "51228/51228 [==============================] - 2s 40us/step - loss: 0.1090 - accuracy: 0.9486 - val_loss: 0.1843 - val_accuracy: 0.9114\n",
      "Epoch 21/200\n",
      "51228/51228 [==============================] - 2s 40us/step - loss: 0.1081 - accuracy: 0.9507 - val_loss: 0.1845 - val_accuracy: 0.9113\n",
      "Epoch 22/200\n",
      "51228/51228 [==============================] - 2s 39us/step - loss: 0.1084 - accuracy: 0.9497 - val_loss: 0.1839 - val_accuracy: 0.9127\n",
      "Epoch 23/200\n",
      "51228/51228 [==============================] - 2s 40us/step - loss: 0.1072 - accuracy: 0.9514 - val_loss: 0.1830 - val_accuracy: 0.9123\n",
      "Epoch 24/200\n",
      "51228/51228 [==============================] - 2s 40us/step - loss: 0.1064 - accuracy: 0.9532 - val_loss: 0.1835 - val_accuracy: 0.9129\n",
      "Epoch 25/200\n",
      "51228/51228 [==============================] - 2s 40us/step - loss: 0.1066 - accuracy: 0.9521 - val_loss: 0.1820 - val_accuracy: 0.9111\n",
      "Epoch 26/200\n",
      "51228/51228 [==============================] - 2s 39us/step - loss: 0.1075 - accuracy: 0.9522 - val_loss: 0.1821 - val_accuracy: 0.9117\n",
      "Epoch 27/200\n",
      "51228/51228 [==============================] - 2s 39us/step - loss: 0.1065 - accuracy: 0.9531 - val_loss: 0.1831 - val_accuracy: 0.9128\n",
      "Epoch 28/200\n",
      "51228/51228 [==============================] - 2s 41us/step - loss: 0.1059 - accuracy: 0.9527 - val_loss: 0.1830 - val_accuracy: 0.9128\n",
      "Epoch 29/200\n",
      "51228/51228 [==============================] - 2s 39us/step - loss: 0.1065 - accuracy: 0.9532 - val_loss: 0.1829 - val_accuracy: 0.9128\n",
      "Epoch 30/200\n",
      "51228/51228 [==============================] - 2s 40us/step - loss: 0.1068 - accuracy: 0.9526 - val_loss: 0.1835 - val_accuracy: 0.9128\n",
      "Epoch 31/200\n",
      "51228/51228 [==============================] - 2s 40us/step - loss: 0.1052 - accuracy: 0.9535 - val_loss: 0.1832 - val_accuracy: 0.9126\n",
      "Epoch 32/200\n",
      "51228/51228 [==============================] - 2s 40us/step - loss: 0.1048 - accuracy: 0.9535 - val_loss: 0.1833 - val_accuracy: 0.9124\n",
      "Epoch 33/200\n",
      "51228/51228 [==============================] - 2s 40us/step - loss: 0.1054 - accuracy: 0.9538 - val_loss: 0.1817 - val_accuracy: 0.9128\n",
      "Epoch 34/200\n",
      "51228/51228 [==============================] - 2s 40us/step - loss: 0.1052 - accuracy: 0.9524 - val_loss: 0.1828 - val_accuracy: 0.9122\n",
      "Epoch 35/200\n",
      "51228/51228 [==============================] - 2s 40us/step - loss: 0.1055 - accuracy: 0.9527 - val_loss: 0.1821 - val_accuracy: 0.9134\n",
      "Epoch 36/200\n",
      "51228/51228 [==============================] - 2s 40us/step - loss: 0.1063 - accuracy: 0.9523 - val_loss: 0.1840 - val_accuracy: 0.9118\n",
      "Epoch 37/200\n",
      "51228/51228 [==============================] - 2s 39us/step - loss: 0.1056 - accuracy: 0.9535 - val_loss: 0.1859 - val_accuracy: 0.9125\n",
      "Epoch 38/200\n",
      "51228/51228 [==============================] - 2s 40us/step - loss: 0.1055 - accuracy: 0.9535 - val_loss: 0.1842 - val_accuracy: 0.9127\n",
      "Epoch 39/200\n",
      "51228/51228 [==============================] - 2s 40us/step - loss: 0.1055 - accuracy: 0.9533 - val_loss: 0.1850 - val_accuracy: 0.9128\n",
      "Epoch 40/200\n",
      "51228/51228 [==============================] - 2s 39us/step - loss: 0.1055 - accuracy: 0.9528 - val_loss: 0.1836 - val_accuracy: 0.9121\n",
      "Epoch 41/200\n",
      "51228/51228 [==============================] - 2s 39us/step - loss: 0.1049 - accuracy: 0.9525 - val_loss: 0.1848 - val_accuracy: 0.9115\n",
      "Epoch 42/200\n",
      "51228/51228 [==============================] - 2s 39us/step - loss: 0.1044 - accuracy: 0.9528 - val_loss: 0.1872 - val_accuracy: 0.9099\n",
      "Epoch 43/200\n",
      "51228/51228 [==============================] - 2s 40us/step - loss: 0.1056 - accuracy: 0.9536 - val_loss: 0.1854 - val_accuracy: 0.9115\n",
      "Epoch 44/200\n",
      "51228/51228 [==============================] - 2s 39us/step - loss: 0.1043 - accuracy: 0.9534 - val_loss: 0.1864 - val_accuracy: 0.9110\n",
      "Epoch 45/200\n",
      "51228/51228 [==============================] - 2s 39us/step - loss: 0.1050 - accuracy: 0.9536 - val_loss: 0.1840 - val_accuracy: 0.9111\n",
      "Epoch 46/200\n",
      "51228/51228 [==============================] - 2s 40us/step - loss: 0.1036 - accuracy: 0.9533 - val_loss: 0.1858 - val_accuracy: 0.9111\n",
      "Epoch 47/200\n",
      "51228/51228 [==============================] - 2s 39us/step - loss: 0.1035 - accuracy: 0.9533 - val_loss: 0.1844 - val_accuracy: 0.9097\n",
      "Epoch 48/200\n",
      "51228/51228 [==============================] - 2s 40us/step - loss: 0.1039 - accuracy: 0.9529 - val_loss: 0.1867 - val_accuracy: 0.9103\n",
      "Epoch 49/200\n",
      "51228/51228 [==============================] - 2s 39us/step - loss: 0.1035 - accuracy: 0.9528 - val_loss: 0.1866 - val_accuracy: 0.9103\n",
      "Epoch 50/200\n",
      "51228/51228 [==============================] - 2s 38us/step - loss: 0.1045 - accuracy: 0.9529 - val_loss: 0.1855 - val_accuracy: 0.9105\n",
      "Epoch 51/200\n",
      "51228/51228 [==============================] - 2s 37us/step - loss: 0.1048 - accuracy: 0.9533 - val_loss: 0.1866 - val_accuracy: 0.9108\n",
      "Epoch 52/200\n",
      "51228/51228 [==============================] - 2s 36us/step - loss: 0.1038 - accuracy: 0.9535 - val_loss: 0.1864 - val_accuracy: 0.9105\n",
      "Epoch 53/200\n",
      "51228/51228 [==============================] - 2s 39us/step - loss: 0.1040 - accuracy: 0.9532 - val_loss: 0.1861 - val_accuracy: 0.9107\n",
      "Epoch 54/200\n",
      "51228/51228 [==============================] - 2s 39us/step - loss: 0.1045 - accuracy: 0.9531 - val_loss: 0.1861 - val_accuracy: 0.9101\n",
      "Epoch 55/200\n",
      "51228/51228 [==============================] - 2s 40us/step - loss: 0.1039 - accuracy: 0.9535 - val_loss: 0.1847 - val_accuracy: 0.9114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/200\n",
      "51228/51228 [==============================] - 2s 39us/step - loss: 0.1042 - accuracy: 0.9538 - val_loss: 0.1849 - val_accuracy: 0.9117\n",
      "Epoch 57/200\n",
      "51228/51228 [==============================] - 2s 39us/step - loss: 0.1040 - accuracy: 0.9541 - val_loss: 0.1855 - val_accuracy: 0.9104\n",
      "Epoch 58/200\n",
      "51228/51228 [==============================] - 2s 39us/step - loss: 0.1033 - accuracy: 0.9538 - val_loss: 0.1856 - val_accuracy: 0.9116\n",
      "Epoch 59/200\n",
      "51228/51228 [==============================] - 2s 37us/step - loss: 0.1045 - accuracy: 0.9529 - val_loss: 0.1860 - val_accuracy: 0.9098\n",
      "Epoch 60/200\n",
      "51228/51228 [==============================] - 2s 37us/step - loss: 0.1041 - accuracy: 0.9535 - val_loss: 0.1858 - val_accuracy: 0.9110\n",
      "Epoch 61/200\n",
      "51228/51228 [==============================] - 2s 39us/step - loss: 0.1034 - accuracy: 0.9536 - val_loss: 0.1889 - val_accuracy: 0.9100\n",
      "Epoch 62/200\n",
      "51228/51228 [==============================] - 2s 39us/step - loss: 0.1037 - accuracy: 0.9535 - val_loss: 0.1857 - val_accuracy: 0.9103\n",
      "Epoch 63/200\n",
      "51228/51228 [==============================] - 2s 40us/step - loss: 0.1031 - accuracy: 0.9534 - val_loss: 0.1852 - val_accuracy: 0.9111\n",
      "Epoch 64/200\n",
      "51228/51228 [==============================] - 2s 40us/step - loss: 0.1032 - accuracy: 0.9540 - val_loss: 0.1844 - val_accuracy: 0.9102\n",
      "Epoch 65/200\n",
      "51228/51228 [==============================] - 2s 39us/step - loss: 0.1041 - accuracy: 0.9531 - val_loss: 0.1851 - val_accuracy: 0.9113\n",
      "Epoch 66/200\n",
      "51228/51228 [==============================] - 2s 39us/step - loss: 0.1038 - accuracy: 0.9541 - val_loss: 0.1856 - val_accuracy: 0.9115\n",
      "Epoch 67/200\n",
      "51228/51228 [==============================] - 2s 39us/step - loss: 0.1027 - accuracy: 0.9543 - val_loss: 0.1839 - val_accuracy: 0.9112\n",
      "Epoch 68/200\n",
      "51228/51228 [==============================] - 2s 40us/step - loss: 0.1037 - accuracy: 0.9537 - val_loss: 0.1835 - val_accuracy: 0.9124\n",
      "Epoch 69/200\n",
      "51228/51228 [==============================] - 2s 46us/step - loss: 0.1032 - accuracy: 0.9531 - val_loss: 0.1842 - val_accuracy: 0.9108\n",
      "Epoch 70/200\n",
      "51228/51228 [==============================] - 2s 41us/step - loss: 0.1030 - accuracy: 0.9541 - val_loss: 0.1843 - val_accuracy: 0.9111\n",
      "Epoch 71/200\n",
      "51228/51228 [==============================] - 2s 41us/step - loss: 0.1034 - accuracy: 0.9536 - val_loss: 0.1846 - val_accuracy: 0.9115\n",
      "Epoch 72/200\n",
      "51228/51228 [==============================] - 2s 36us/step - loss: 0.1040 - accuracy: 0.9532 - val_loss: 0.1858 - val_accuracy: 0.9092\n",
      "Epoch 73/200\n",
      "51228/51228 [==============================] - 2s 37us/step - loss: 0.1033 - accuracy: 0.9541 - val_loss: 0.1870 - val_accuracy: 0.9099\n",
      "Epoch 74/200\n",
      "51228/51228 [==============================] - 2s 36us/step - loss: 0.1037 - accuracy: 0.9540 - val_loss: 0.1866 - val_accuracy: 0.9100\n",
      "Epoch 75/200\n",
      "51228/51228 [==============================] - 2s 38us/step - loss: 0.1040 - accuracy: 0.9537 - val_loss: 0.1882 - val_accuracy: 0.9088\n",
      "Epoch 76/200\n",
      "51228/51228 [==============================] - 2s 38us/step - loss: 0.1037 - accuracy: 0.9538 - val_loss: 0.1877 - val_accuracy: 0.9111\n",
      "Epoch 77/200\n",
      "51228/51228 [==============================] - 2s 37us/step - loss: 0.1031 - accuracy: 0.9541 - val_loss: 0.1874 - val_accuracy: 0.9093\n",
      "Epoch 78/200\n",
      "51228/51228 [==============================] - 2s 37us/step - loss: 0.1033 - accuracy: 0.9536 - val_loss: 0.1855 - val_accuracy: 0.9110\n",
      "Epoch 79/200\n",
      "51228/51228 [==============================] - 2s 37us/step - loss: 0.1028 - accuracy: 0.9536 - val_loss: 0.1866 - val_accuracy: 0.9095\n",
      "Epoch 80/200\n",
      "51228/51228 [==============================] - 2s 37us/step - loss: 0.1024 - accuracy: 0.9539 - val_loss: 0.1860 - val_accuracy: 0.9120\n",
      "Epoch 81/200\n",
      "51228/51228 [==============================] - 2s 36us/step - loss: 0.1032 - accuracy: 0.9538 - val_loss: 0.1853 - val_accuracy: 0.9110\n",
      "Epoch 82/200\n",
      "51228/51228 [==============================] - 2s 37us/step - loss: 0.1032 - accuracy: 0.9539 - val_loss: 0.1855 - val_accuracy: 0.9114\n",
      "Epoch 83/200\n",
      "51228/51228 [==============================] - 2s 36us/step - loss: 0.1025 - accuracy: 0.9545 - val_loss: 0.1850 - val_accuracy: 0.9115\n",
      "Epoch 84/200\n",
      "51228/51228 [==============================] - 2s 36us/step - loss: 0.1031 - accuracy: 0.9536 - val_loss: 0.1853 - val_accuracy: 0.9111\n",
      "Epoch 85/200\n",
      "51228/51228 [==============================] - 2s 37us/step - loss: 0.1030 - accuracy: 0.9533 - val_loss: 0.1847 - val_accuracy: 0.9113\n",
      "Epoch 86/200\n",
      "51228/51228 [==============================] - 2s 37us/step - loss: 0.1028 - accuracy: 0.9541 - val_loss: 0.1854 - val_accuracy: 0.9118\n",
      "Epoch 87/200\n",
      "51228/51228 [==============================] - 2s 38us/step - loss: 0.1031 - accuracy: 0.9539 - val_loss: 0.1854 - val_accuracy: 0.9120\n",
      "Epoch 88/200\n",
      "51228/51228 [==============================] - 2s 37us/step - loss: 0.1032 - accuracy: 0.9538 - val_loss: 0.1858 - val_accuracy: 0.9131\n",
      "Epoch 89/200\n",
      "51228/51228 [==============================] - 2s 36us/step - loss: 0.1032 - accuracy: 0.9538 - val_loss: 0.1869 - val_accuracy: 0.9116\n",
      "Epoch 90/200\n",
      "51228/51228 [==============================] - 2s 37us/step - loss: 0.1027 - accuracy: 0.9535 - val_loss: 0.1857 - val_accuracy: 0.9104\n",
      "Epoch 91/200\n",
      "51228/51228 [==============================] - 2s 37us/step - loss: 0.1031 - accuracy: 0.9536 - val_loss: 0.1849 - val_accuracy: 0.9115\n",
      "Epoch 92/200\n",
      "51228/51228 [==============================] - 2s 36us/step - loss: 0.1026 - accuracy: 0.9542 - val_loss: 0.1879 - val_accuracy: 0.9114\n",
      "Epoch 93/200\n",
      "51228/51228 [==============================] - 2s 38us/step - loss: 0.1031 - accuracy: 0.9541 - val_loss: 0.1852 - val_accuracy: 0.9103\n",
      "Epoch 94/200\n",
      "51228/51228 [==============================] - 2s 36us/step - loss: 0.1028 - accuracy: 0.9537 - val_loss: 0.1873 - val_accuracy: 0.9114\n",
      "Epoch 95/200\n",
      "51228/51228 [==============================] - 2s 37us/step - loss: 0.1030 - accuracy: 0.9535 - val_loss: 0.1860 - val_accuracy: 0.9111\n",
      "Epoch 96/200\n",
      "51228/51228 [==============================] - 2s 37us/step - loss: 0.1025 - accuracy: 0.9540 - val_loss: 0.1860 - val_accuracy: 0.9106\n",
      "Epoch 97/200\n",
      "51228/51228 [==============================] - 2s 37us/step - loss: 0.1024 - accuracy: 0.9541 - val_loss: 0.1866 - val_accuracy: 0.9103\n",
      "Epoch 98/200\n",
      "51228/51228 [==============================] - 2s 36us/step - loss: 0.1029 - accuracy: 0.9534 - val_loss: 0.1858 - val_accuracy: 0.9103\n",
      "Epoch 99/200\n",
      "51228/51228 [==============================] - 2s 38us/step - loss: 0.1024 - accuracy: 0.9541 - val_loss: 0.1857 - val_accuracy: 0.9089\n",
      "Epoch 100/200\n",
      "51228/51228 [==============================] - 2s 37us/step - loss: 0.1031 - accuracy: 0.9537 - val_loss: 0.1868 - val_accuracy: 0.9086\n",
      "Epoch 101/200\n",
      "51228/51228 [==============================] - 2s 37us/step - loss: 0.1019 - accuracy: 0.9546 - val_loss: 0.1858 - val_accuracy: 0.9101\n",
      "Epoch 102/200\n",
      "51228/51228 [==============================] - 2s 37us/step - loss: 0.1024 - accuracy: 0.9541 - val_loss: 0.1869 - val_accuracy: 0.9099\n",
      "Epoch 103/200\n",
      "51228/51228 [==============================] - 2s 37us/step - loss: 0.1035 - accuracy: 0.9540 - val_loss: 0.1856 - val_accuracy: 0.9106\n",
      "Epoch 104/200\n",
      "51228/51228 [==============================] - 2s 37us/step - loss: 0.1026 - accuracy: 0.9536 - val_loss: 0.1867 - val_accuracy: 0.9090\n",
      "Epoch 105/200\n",
      "51228/51228 [==============================] - 2s 36us/step - loss: 0.1025 - accuracy: 0.9548 - val_loss: 0.1863 - val_accuracy: 0.9120\n",
      "Epoch 106/200\n",
      "51228/51228 [==============================] - 2s 37us/step - loss: 0.1026 - accuracy: 0.9537 - val_loss: 0.1858 - val_accuracy: 0.9094\n",
      "Epoch 107/200\n",
      "51228/51228 [==============================] - 2s 37us/step - loss: 0.1031 - accuracy: 0.9534 - val_loss: 0.1878 - val_accuracy: 0.9099\n",
      "Epoch 108/200\n",
      "51228/51228 [==============================] - 2s 37us/step - loss: 0.1020 - accuracy: 0.9537 - val_loss: 0.1846 - val_accuracy: 0.9099\n",
      "Epoch 109/200\n",
      "51228/51228 [==============================] - 2s 37us/step - loss: 0.1020 - accuracy: 0.9547 - val_loss: 0.1869 - val_accuracy: 0.9090\n",
      "Epoch 110/200\n",
      "51228/51228 [==============================] - 2s 37us/step - loss: 0.1024 - accuracy: 0.9545 - val_loss: 0.1872 - val_accuracy: 0.9086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/200\n",
      "51228/51228 [==============================] - 2s 37us/step - loss: 0.1019 - accuracy: 0.9543 - val_loss: 0.1869 - val_accuracy: 0.9099\n",
      "Epoch 112/200\n",
      "51228/51228 [==============================] - 2s 37us/step - loss: 0.1014 - accuracy: 0.9541 - val_loss: 0.1868 - val_accuracy: 0.9110\n",
      "Epoch 113/200\n",
      "51228/51228 [==============================] - 2s 38us/step - loss: 0.1025 - accuracy: 0.9536 - val_loss: 0.1860 - val_accuracy: 0.9091\n",
      "Epoch 114/200\n",
      "51228/51228 [==============================] - 2s 37us/step - loss: 0.1030 - accuracy: 0.9541 - val_loss: 0.1856 - val_accuracy: 0.9095\n",
      "Epoch 115/200\n",
      "51228/51228 [==============================] - 2s 37us/step - loss: 0.1034 - accuracy: 0.9539 - val_loss: 0.1884 - val_accuracy: 0.9082\n",
      "Epoch 116/200\n",
      "51228/51228 [==============================] - 2s 37us/step - loss: 0.1025 - accuracy: 0.9537 - val_loss: 0.1875 - val_accuracy: 0.9097\n",
      "Epoch 117/200\n",
      "51228/51228 [==============================] - 2s 36us/step - loss: 0.1020 - accuracy: 0.9544 - val_loss: 0.1887 - val_accuracy: 0.9092\n",
      "Epoch 118/200\n",
      "51228/51228 [==============================] - 2s 36us/step - loss: 0.1025 - accuracy: 0.9544 - val_loss: 0.1874 - val_accuracy: 0.9085\n",
      "Epoch 119/200\n",
      "51228/51228 [==============================] - 2s 37us/step - loss: 0.1025 - accuracy: 0.9541 - val_loss: 0.1882 - val_accuracy: 0.9090\n",
      "Epoch 120/200\n",
      "51228/51228 [==============================] - 2s 37us/step - loss: 0.1022 - accuracy: 0.9549 - val_loss: 0.1866 - val_accuracy: 0.9103\n",
      "Epoch 121/200\n",
      "51228/51228 [==============================] - 2s 36us/step - loss: 0.1019 - accuracy: 0.9538 - val_loss: 0.1884 - val_accuracy: 0.9094\n",
      "Epoch 122/200\n",
      "51228/51228 [==============================] - 2s 37us/step - loss: 0.1026 - accuracy: 0.9543 - val_loss: 0.1868 - val_accuracy: 0.9103\n",
      "Epoch 123/200\n",
      "51228/51228 [==============================] - 2s 37us/step - loss: 0.1004 - accuracy: 0.9546 - val_loss: 0.1882 - val_accuracy: 0.9099\n",
      "Epoch 124/200\n",
      "51228/51228 [==============================] - 2s 36us/step - loss: 0.1019 - accuracy: 0.9544 - val_loss: 0.1877 - val_accuracy: 0.9098\n",
      "Epoch 125/200\n",
      "51228/51228 [==============================] - 2s 37us/step - loss: 0.1023 - accuracy: 0.9543 - val_loss: 0.1865 - val_accuracy: 0.9090\n",
      "Epoch 126/200\n",
      "51228/51228 [==============================] - 2s 36us/step - loss: 0.1013 - accuracy: 0.9538 - val_loss: 0.1877 - val_accuracy: 0.9100\n",
      "Epoch 127/200\n",
      "51228/51228 [==============================] - 2s 36us/step - loss: 0.1025 - accuracy: 0.9537 - val_loss: 0.1857 - val_accuracy: 0.9098\n",
      "Epoch 128/200\n",
      "51228/51228 [==============================] - 2s 36us/step - loss: 0.1024 - accuracy: 0.9541 - val_loss: 0.1863 - val_accuracy: 0.9093\n",
      "Epoch 129/200\n",
      "51228/51228 [==============================] - 2s 37us/step - loss: 0.1018 - accuracy: 0.9545 - val_loss: 0.1873 - val_accuracy: 0.9094\n",
      "Epoch 130/200\n",
      "51228/51228 [==============================] - 2s 36us/step - loss: 0.1025 - accuracy: 0.9538 - val_loss: 0.1858 - val_accuracy: 0.9106\n",
      "Epoch 131/200\n",
      "51228/51228 [==============================] - 2s 37us/step - loss: 0.1023 - accuracy: 0.9540 - val_loss: 0.1873 - val_accuracy: 0.9117\n",
      "Epoch 132/200\n",
      "51228/51228 [==============================] - 2s 37us/step - loss: 0.1021 - accuracy: 0.9550 - val_loss: 0.1874 - val_accuracy: 0.9103\n",
      "Epoch 133/200\n",
      "51228/51228 [==============================] - 2s 37us/step - loss: 0.1016 - accuracy: 0.9542 - val_loss: 0.1876 - val_accuracy: 0.9098\n",
      "Epoch 134/200\n",
      "51228/51228 [==============================] - 2s 38us/step - loss: 0.1016 - accuracy: 0.9538 - val_loss: 0.1892 - val_accuracy: 0.9094\n",
      "Epoch 135/200\n",
      "51228/51228 [==============================] - 2s 37us/step - loss: 0.1017 - accuracy: 0.9545 - val_loss: 0.1870 - val_accuracy: 0.9097\n",
      "Epoch 136/200\n",
      "51228/51228 [==============================] - 2s 34us/step - loss: 0.1023 - accuracy: 0.9539 - val_loss: 0.1861 - val_accuracy: 0.9096\n",
      "Epoch 137/200\n",
      "51228/51228 [==============================] - 2s 35us/step - loss: 0.1014 - accuracy: 0.9546 - val_loss: 0.1865 - val_accuracy: 0.9096\n",
      "Epoch 138/200\n",
      "51228/51228 [==============================] - 2s 34us/step - loss: 0.1023 - accuracy: 0.9553 - val_loss: 0.1867 - val_accuracy: 0.9095\n",
      "Epoch 139/200\n",
      "51228/51228 [==============================] - 2s 35us/step - loss: 0.1007 - accuracy: 0.9539 - val_loss: 0.1881 - val_accuracy: 0.9092\n",
      "Epoch 140/200\n",
      "51228/51228 [==============================] - 2s 34us/step - loss: 0.1017 - accuracy: 0.9542 - val_loss: 0.1887 - val_accuracy: 0.9084\n",
      "Epoch 141/200\n",
      "51228/51228 [==============================] - 2s 34us/step - loss: 0.1027 - accuracy: 0.9546 - val_loss: 0.1863 - val_accuracy: 0.9102\n",
      "Epoch 142/200\n",
      "51228/51228 [==============================] - 2s 37us/step - loss: 0.1020 - accuracy: 0.9541 - val_loss: 0.1881 - val_accuracy: 0.9092\n",
      "Epoch 143/200\n",
      "51228/51228 [==============================] - 2s 37us/step - loss: 0.1024 - accuracy: 0.9537 - val_loss: 0.1869 - val_accuracy: 0.9086\n",
      "Epoch 144/200\n",
      "51228/51228 [==============================] - 2s 37us/step - loss: 0.1026 - accuracy: 0.9540 - val_loss: 0.1910 - val_accuracy: 0.9095\n",
      "Epoch 145/200\n",
      "51228/51228 [==============================] - 2s 36us/step - loss: 0.1021 - accuracy: 0.9544 - val_loss: 0.1870 - val_accuracy: 0.9098\n",
      "Epoch 146/200\n",
      "51228/51228 [==============================] - 2s 36us/step - loss: 0.1019 - accuracy: 0.9541 - val_loss: 0.1877 - val_accuracy: 0.9084\n",
      "Epoch 147/200\n",
      "51228/51228 [==============================] - 2s 37us/step - loss: 0.1013 - accuracy: 0.9540 - val_loss: 0.1874 - val_accuracy: 0.9093\n",
      "Epoch 148/200\n",
      "51228/51228 [==============================] - 2s 35us/step - loss: 0.1016 - accuracy: 0.9549 - val_loss: 0.1888 - val_accuracy: 0.9103\n",
      "Epoch 149/200\n",
      "51228/51228 [==============================] - 2s 34us/step - loss: 0.1016 - accuracy: 0.9550 - val_loss: 0.1867 - val_accuracy: 0.9089\n",
      "Epoch 150/200\n",
      "51228/51228 [==============================] - 2s 35us/step - loss: 0.1021 - accuracy: 0.9545 - val_loss: 0.1863 - val_accuracy: 0.9102\n",
      "Epoch 151/200\n",
      "51228/51228 [==============================] - 2s 35us/step - loss: 0.1016 - accuracy: 0.9551 - val_loss: 0.1901 - val_accuracy: 0.9103\n",
      "Epoch 152/200\n",
      "51228/51228 [==============================] - 2s 34us/step - loss: 0.1007 - accuracy: 0.9548 - val_loss: 0.1887 - val_accuracy: 0.9102\n",
      "Epoch 153/200\n",
      "51228/51228 [==============================] - 2s 35us/step - loss: 0.1013 - accuracy: 0.9546 - val_loss: 0.1878 - val_accuracy: 0.9115\n",
      "Epoch 154/200\n",
      "51228/51228 [==============================] - 2s 34us/step - loss: 0.1018 - accuracy: 0.9548 - val_loss: 0.1888 - val_accuracy: 0.9094\n",
      "Epoch 155/200\n",
      "51228/51228 [==============================] - 2s 33us/step - loss: 0.1018 - accuracy: 0.9536 - val_loss: 0.1874 - val_accuracy: 0.9111\n",
      "Epoch 156/200\n",
      "51228/51228 [==============================] - 2s 35us/step - loss: 0.1013 - accuracy: 0.9546 - val_loss: 0.1868 - val_accuracy: 0.9116\n",
      "Epoch 157/200\n",
      "51228/51228 [==============================] - 2s 34us/step - loss: 0.1017 - accuracy: 0.9542 - val_loss: 0.1867 - val_accuracy: 0.9100\n",
      "Epoch 158/200\n",
      "51228/51228 [==============================] - 2s 35us/step - loss: 0.1027 - accuracy: 0.9539 - val_loss: 0.1891 - val_accuracy: 0.9099\n",
      "Epoch 159/200\n",
      "51228/51228 [==============================] - 2s 34us/step - loss: 0.1016 - accuracy: 0.9535 - val_loss: 0.1866 - val_accuracy: 0.9100\n",
      "Epoch 160/200\n",
      "51228/51228 [==============================] - 2s 34us/step - loss: 0.1015 - accuracy: 0.9546 - val_loss: 0.1902 - val_accuracy: 0.9104\n",
      "Epoch 161/200\n",
      "51228/51228 [==============================] - 2s 38us/step - loss: 0.1016 - accuracy: 0.9544 - val_loss: 0.1872 - val_accuracy: 0.9108\n",
      "Epoch 162/200\n",
      "51228/51228 [==============================] - 2s 40us/step - loss: 0.0997 - accuracy: 0.9550 - val_loss: 0.1888 - val_accuracy: 0.9104\n",
      "Epoch 163/200\n",
      "51228/51228 [==============================] - 2s 39us/step - loss: 0.0998 - accuracy: 0.9550 - val_loss: 0.1899 - val_accuracy: 0.9102\n",
      "Epoch 164/200\n",
      "51228/51228 [==============================] - 2s 38us/step - loss: 0.1017 - accuracy: 0.9546 - val_loss: 0.1896 - val_accuracy: 0.9105\n",
      "Epoch 165/200\n",
      "51228/51228 [==============================] - 2s 40us/step - loss: 0.1016 - accuracy: 0.9548 - val_loss: 0.1862 - val_accuracy: 0.9099\n",
      "Epoch 166/200\n",
      "51228/51228 [==============================] - 2s 40us/step - loss: 0.1012 - accuracy: 0.9540 - val_loss: 0.1882 - val_accuracy: 0.9098\n",
      "Epoch 167/200\n",
      "51228/51228 [==============================] - 2s 39us/step - loss: 0.1018 - accuracy: 0.9544 - val_loss: 0.1884 - val_accuracy: 0.9094\n",
      "Epoch 168/200\n",
      "51228/51228 [==============================] - 2s 40us/step - loss: 0.1005 - accuracy: 0.9549 - val_loss: 0.1892 - val_accuracy: 0.9104\n",
      "Epoch 169/200\n",
      "51228/51228 [==============================] - 2s 41us/step - loss: 0.1018 - accuracy: 0.9543 - val_loss: 0.1880 - val_accuracy: 0.9100\n",
      "Epoch 170/200\n",
      "51228/51228 [==============================] - 2s 40us/step - loss: 0.1024 - accuracy: 0.9536 - val_loss: 0.1881 - val_accuracy: 0.9101\n",
      "Epoch 171/200\n",
      "51228/51228 [==============================] - 2s 40us/step - loss: 0.1009 - accuracy: 0.9549 - val_loss: 0.1878 - val_accuracy: 0.9095\n",
      "Epoch 172/200\n",
      "51228/51228 [==============================] - 2s 40us/step - loss: 0.1020 - accuracy: 0.9550 - val_loss: 0.1863 - val_accuracy: 0.9092\n",
      "Epoch 173/200\n",
      "51228/51228 [==============================] - 2s 39us/step - loss: 0.1014 - accuracy: 0.9553 - val_loss: 0.1887 - val_accuracy: 0.9089\n",
      "Epoch 174/200\n",
      "51228/51228 [==============================] - 2s 39us/step - loss: 0.1007 - accuracy: 0.9545 - val_loss: 0.1875 - val_accuracy: 0.9092\n",
      "Epoch 175/200\n",
      "51228/51228 [==============================] - 2s 40us/step - loss: 0.1010 - accuracy: 0.9540 - val_loss: 0.1888 - val_accuracy: 0.9082\n",
      "Epoch 176/200\n",
      "51228/51228 [==============================] - 2s 41us/step - loss: 0.1008 - accuracy: 0.9548 - val_loss: 0.1906 - val_accuracy: 0.9093\n",
      "Epoch 177/200\n",
      "51228/51228 [==============================] - 2s 38us/step - loss: 0.1009 - accuracy: 0.9551 - val_loss: 0.1880 - val_accuracy: 0.9084\n",
      "Epoch 178/200\n",
      "51228/51228 [==============================] - 2s 39us/step - loss: 0.1006 - accuracy: 0.9545 - val_loss: 0.1899 - val_accuracy: 0.9100\n",
      "Epoch 179/200\n",
      "51228/51228 [==============================] - 2s 40us/step - loss: 0.1011 - accuracy: 0.9546 - val_loss: 0.1890 - val_accuracy: 0.9098\n",
      "Epoch 180/200\n",
      "51228/51228 [==============================] - 2s 42us/step - loss: 0.1019 - accuracy: 0.9540 - val_loss: 0.1878 - val_accuracy: 0.9091\n",
      "Epoch 181/200\n",
      "51228/51228 [==============================] - 2s 41us/step - loss: 0.1017 - accuracy: 0.9544 - val_loss: 0.1874 - val_accuracy: 0.9096\n",
      "Epoch 182/200\n",
      "51228/51228 [==============================] - 2s 41us/step - loss: 0.1008 - accuracy: 0.9548 - val_loss: 0.1894 - val_accuracy: 0.9094\n",
      "Epoch 183/200\n",
      "51228/51228 [==============================] - 2s 42us/step - loss: 0.1015 - accuracy: 0.9544 - val_loss: 0.1879 - val_accuracy: 0.9094\n",
      "Epoch 184/200\n",
      "51228/51228 [==============================] - 2s 43us/step - loss: 0.1012 - accuracy: 0.9550 - val_loss: 0.1870 - val_accuracy: 0.9100\n",
      "Epoch 185/200\n",
      "51228/51228 [==============================] - 2s 42us/step - loss: 0.1011 - accuracy: 0.9544 - val_loss: 0.1873 - val_accuracy: 0.9106\n",
      "Epoch 186/200\n",
      "51228/51228 [==============================] - 2s 42us/step - loss: 0.1013 - accuracy: 0.9534 - val_loss: 0.1870 - val_accuracy: 0.9107\n",
      "Epoch 187/200\n",
      "51228/51228 [==============================] - 2s 42us/step - loss: 0.1004 - accuracy: 0.9540 - val_loss: 0.1889 - val_accuracy: 0.9099\n",
      "Epoch 188/200\n",
      "51228/51228 [==============================] - 2s 41us/step - loss: 0.1009 - accuracy: 0.9543 - val_loss: 0.1858 - val_accuracy: 0.9099\n",
      "Epoch 189/200\n",
      "51228/51228 [==============================] - 2s 41us/step - loss: 0.1014 - accuracy: 0.9540 - val_loss: 0.1868 - val_accuracy: 0.9096\n",
      "Epoch 190/200\n",
      "51228/51228 [==============================] - 2s 40us/step - loss: 0.1003 - accuracy: 0.9554 - val_loss: 0.1875 - val_accuracy: 0.9102\n",
      "Epoch 191/200\n",
      "51228/51228 [==============================] - 2s 41us/step - loss: 0.1019 - accuracy: 0.9545 - val_loss: 0.1896 - val_accuracy: 0.9106\n",
      "Epoch 192/200\n",
      "51228/51228 [==============================] - 2s 41us/step - loss: 0.1013 - accuracy: 0.9547 - val_loss: 0.1890 - val_accuracy: 0.9104\n",
      "Epoch 193/200\n",
      "51228/51228 [==============================] - 2s 40us/step - loss: 0.1014 - accuracy: 0.9545 - val_loss: 0.1885 - val_accuracy: 0.9093\n",
      "Epoch 194/200\n",
      "51228/51228 [==============================] - 2s 39us/step - loss: 0.1013 - accuracy: 0.9543 - val_loss: 0.1868 - val_accuracy: 0.9116\n",
      "Epoch 195/200\n",
      "51228/51228 [==============================] - 2s 40us/step - loss: 0.1009 - accuracy: 0.9545 - val_loss: 0.1872 - val_accuracy: 0.9097\n",
      "Epoch 196/200\n",
      "51228/51228 [==============================] - 2s 39us/step - loss: 0.1012 - accuracy: 0.9553 - val_loss: 0.1882 - val_accuracy: 0.9098\n",
      "Epoch 197/200\n",
      "51228/51228 [==============================] - 2s 40us/step - loss: 0.1014 - accuracy: 0.9545 - val_loss: 0.1870 - val_accuracy: 0.9102\n",
      "Epoch 198/200\n",
      "51228/51228 [==============================] - 5s 102us/step - loss: 0.1018 - accuracy: 0.9549 - val_loss: 0.1894 - val_accuracy: 0.9084\n",
      "Epoch 199/200\n",
      "51228/51228 [==============================] - 14s 281us/step - loss: 0.1009 - accuracy: 0.9540 - val_loss: 0.1871 - val_accuracy: 0.9099\n",
      "Epoch 200/200\n",
      "51228/51228 [==============================] - 12s 229us/step - loss: 0.1011 - accuracy: 0.9542 - val_loss: 0.1868 - val_accuracy: 0.9107\n"
     ]
    }
   ],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "sgd = optimizers.SGD(lr=0.01)\n",
    "\n",
    "modelSMOTE.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "modelFitSMOTE=modelSMOTE.fit(X_SMOTE_std, y_SMOTE, epochs=200, batch_size=64, verbose=1,validation_data=(X_test_std, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(modelFitSMOTE.history['accuracy'][1:])\n",
    "plt.plot(modelFitSMOTE.history['val_accuracy'][1:])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(modelFitSMOTE.history['loss'][1:])\n",
    "plt.plot(modelFitSMOTE.history['val_loss'][1:])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 91.12%\n",
      "Balanced Accuracy: 73.37%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95     10934\n",
      "           1       0.65      0.50      0.57      1423\n",
      "\n",
      "    accuracy                           0.91     12357\n",
      "   macro avg       0.79      0.73      0.76     12357\n",
      "weighted avg       0.90      0.91      0.91     12357\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = modelSMOTE.predict_classes(X_test_std)\n",
    "\n",
    "print(f\"Accuracy: {round(metrics.accuracy_score(y_test, y_pred)*100, 2)}%\")\n",
    "print(f\"Balanced Accuracy: {round(metrics.balanced_accuracy_score(y_test, y_pred)*100, 2)}%\")\n",
    "\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "sgd = optimizers.SGD(lr=0.01, clipnorm=1.)\n",
    "\n",
    "def create_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(16, input_dim=58, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))   \n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'],use_multiprocessing=True)\n",
    "    return model\n",
    "\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "ename": "PicklingError",
     "evalue": "Could not pickle the task to send it to the workers.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/lkgupta/.local/lib/python3.6/site-packages/joblib/externals/loky/backend/queues.py\", line 150, in _feed\n    obj_ = dumps(obj, reducers=reducers)\n  File \"/home/lkgupta/.local/lib/python3.6/site-packages/joblib/externals/loky/backend/reduction.py\", line 247, in dumps\n    dump(obj, buf, reducers=reducers, protocol=protocol)\n  File \"/home/lkgupta/.local/lib/python3.6/site-packages/joblib/externals/loky/backend/reduction.py\", line 240, in dump\n    _LokyPickler(file, reducers=reducers, protocol=protocol).dump(obj)\n  File \"/home/lkgupta/.local/lib/python3.6/site-packages/joblib/externals/cloudpickle/cloudpickle.py\", line 482, in dump\n    return Pickler.dump(self, obj)\n  File \"/usr/lib/python3.6/pickle.py\", line 409, in dump\n    self.save(obj)\n  File \"/usr/lib/python3.6/pickle.py\", line 521, in save\n    self.save_reduce(obj=obj, *rv)\n  File \"/usr/lib/python3.6/pickle.py\", line 634, in save_reduce\n    save(state)\n  File \"/usr/lib/python3.6/pickle.py\", line 476, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"/usr/lib/python3.6/pickle.py\", line 821, in save_dict\n    self._batch_setitems(obj.items())\n  File \"/usr/lib/python3.6/pickle.py\", line 847, in _batch_setitems\n    save(v)\n  File \"/usr/lib/python3.6/pickle.py\", line 521, in save\n    self.save_reduce(obj=obj, *rv)\n  File \"/usr/lib/python3.6/pickle.py\", line 634, in save_reduce\n    save(state)\n  File \"/usr/lib/python3.6/pickle.py\", line 476, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"/usr/lib/python3.6/pickle.py\", line 821, in save_dict\n    self._batch_setitems(obj.items())\n  File \"/usr/lib/python3.6/pickle.py\", line 852, in _batch_setitems\n    save(v)\n  File \"/usr/lib/python3.6/pickle.py\", line 521, in save\n    self.save_reduce(obj=obj, *rv)\n  File \"/usr/lib/python3.6/pickle.py\", line 634, in save_reduce\n    save(state)\n  File \"/usr/lib/python3.6/pickle.py\", line 476, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"/usr/lib/python3.6/pickle.py\", line 821, in save_dict\n    self._batch_setitems(obj.items())\n  File \"/usr/lib/python3.6/pickle.py\", line 847, in _batch_setitems\n    save(v)\n  File \"/usr/lib/python3.6/pickle.py\", line 476, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"/usr/lib/python3.6/pickle.py\", line 781, in save_list\n    self._batch_appends(obj)\n  File \"/usr/lib/python3.6/pickle.py\", line 808, in _batch_appends\n    save(tmp[0])\n  File \"/usr/lib/python3.6/pickle.py\", line 476, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"/usr/lib/python3.6/pickle.py\", line 736, in save_tuple\n    save(element)\n  File \"/usr/lib/python3.6/pickle.py\", line 476, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"/usr/lib/python3.6/pickle.py\", line 736, in save_tuple\n    save(element)\n  File \"/usr/lib/python3.6/pickle.py\", line 521, in save\n    self.save_reduce(obj=obj, *rv)\n  File \"/usr/lib/python3.6/pickle.py\", line 634, in save_reduce\n    save(state)\n  File \"/usr/lib/python3.6/pickle.py\", line 476, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"/usr/lib/python3.6/pickle.py\", line 821, in save_dict\n    self._batch_setitems(obj.items())\n  File \"/usr/lib/python3.6/pickle.py\", line 847, in _batch_setitems\n    save(v)\n  File \"/usr/lib/python3.6/pickle.py\", line 476, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"/home/lkgupta/.local/lib/python3.6/site-packages/joblib/externals/cloudpickle/cloudpickle.py\", line 556, in save_function\n    return self.save_function_tuple(obj)\n  File \"/home/lkgupta/.local/lib/python3.6/site-packages/joblib/externals/cloudpickle/cloudpickle.py\", line 758, in save_function_tuple\n    save(state)\n  File \"/usr/lib/python3.6/pickle.py\", line 476, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"/usr/lib/python3.6/pickle.py\", line 821, in save_dict\n    self._batch_setitems(obj.items())\n  File \"/usr/lib/python3.6/pickle.py\", line 847, in _batch_setitems\n    save(v)\n  File \"/usr/lib/python3.6/pickle.py\", line 476, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"/usr/lib/python3.6/pickle.py\", line 821, in save_dict\n    self._batch_setitems(obj.items())\n  File \"/usr/lib/python3.6/pickle.py\", line 847, in _batch_setitems\n    save(v)\n  File \"/usr/lib/python3.6/pickle.py\", line 521, in save\n    self.save_reduce(obj=obj, *rv)\n  File \"/usr/lib/python3.6/pickle.py\", line 634, in save_reduce\n    save(state)\n  File \"/usr/lib/python3.6/pickle.py\", line 476, in save\n    f(self, obj) # Call unbound method with explicit self\n  File \"/usr/lib/python3.6/pickle.py\", line 821, in save_dict\n    self._batch_setitems(obj.items())\n  File \"/usr/lib/python3.6/pickle.py\", line 847, in _batch_setitems\n    save(v)\n  File \"/usr/lib/python3.6/pickle.py\", line 496, in save\n    rv = reduce(self.proto)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py\", line 923, in __reduce__\n    return (ResourceVariable, (self.numpy(),))\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py\", line 687, in numpy\n    \"numpy() is only available when eager execution is enabled.\")\nNotImplementedError: numpy() is only available when eager execution is enabled.\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-323-b9ef21d8c92d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mparam_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'balanced_accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mgrid_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_SMOTE_std\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_SMOTE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    708\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1151\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    687\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 689\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1017\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1018\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    907\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    910\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    560\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    561\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    423\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPicklingError\u001b[0m: Could not pickle the task to send it to the workers."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
